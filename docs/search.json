[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Foreward",
    "section": "",
    "text": "To Students\nThis OER book is intended to help students in introductory statistics courses. The intended audience is non-science majors. We do not include formal proofs but instead focus on step-by-step examples and try to explain statistical concepts in everyday terms.\n\n\nTo Instructors\nThe techniques used in this book are similar to Mathplosion but updated to use Quarto publishing system.\nThe previous version of this book used (Xie 2019) and the wonderful RMarkdown format. See The R Markdown and knitr Book (Xie 2015)\n\n\nCalvin Williamson and Jennifer R. Shloming\n\n7/20/2023\n The work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\n\nXie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.\n\n\n———. 2019. Bookdown: Authoring Books and Technical Documents with r Markdown. https://CRAN.R-project.org/package=bookdown."
  },
  {
    "objectID": "what-is-statistics.html#what-is-statistics",
    "href": "what-is-statistics.html#what-is-statistics",
    "title": "2  What is Statistics?",
    "section": "2.1 What is Statistics?",
    "text": "2.1 What is Statistics?\nAt this point in time everyone reading this knows the importance of statistics. As we are typing this text, COVID-19 is at the forefront of our everyday lives. Even from home, statistics about this virus is inescapable. Television, newspapers, and all over the Internet we see statistical information now more than ever. We have always had statistics, though. Can you think of some areas where you recall statistical information?\nSome fields include sports, education, politics, real estate, crime, advertisement, economics, and health. One of the authors used to be obsessed with the New York Yankees (especially Derek Jeter) and would know some player stats just for fun. We notice data and graphs more and more since teaching the subject especially when there is a misuse of statistics. While we see statistics a lot we need to be careful what is true. We will get into this more in a bit! We believe you will also notice statistics more after reading this book; please feel free to send us charts or graphs that make you go, “WHAT?!”.\nLet’s go ahead and define statistics:\n\nStatistics is a science that involves the collection, organization, analysis, and interpretation of data.\n\nA major goal in statistics includes summarizing data and drawing conclusions (based on data). Statistics can involve almost any kind of data. You will notice we like to use personal data because that truly is the easiest to obtain!\nSome examples of data that we can all collect pretty easily:\n\n“television” 1 time in a day\nheights\nshoe sizes\nages\nweights\naverage number of times you order in food per week\ncurrent hair colors\nbooks read in a year,\nhours studying for Statistics per week\n\nCan you think of a couple more off the top of your head?\nWe can do statistics with any data set that involves numbers! We do have to make sure that whatever we choose has variation. This means that all the numbers we collect cannot be the same or identical. We can study the ages of professors you currently have but we cannot do statistics with the age of your statistics professor (if it’s just one of us that is)! If you have one statistics professor then you would have the same age written down and only have one entry. We will talk more about this later."
  },
  {
    "objectID": "what-is-statistics.html#footnotes",
    "href": "what-is-statistics.html#footnotes",
    "title": "2  What is Statistics?",
    "section": "",
    "text": "“Television” because at least one of the authors does not have a tv but watches plenty of shows through streaming services.↩︎"
  },
  {
    "objectID": "descriptive-and-inferential.html#descriptive-statistics",
    "href": "descriptive-and-inferential.html#descriptive-statistics",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "3.1 Descriptive Statistics",
    "text": "3.1 Descriptive Statistics\nStatistics techniques used mainly for summarizing data are called descriptive statistics.\nSo, in descriptive statistics the goal is to describe a situation. We want accurate information and then let others know about this data. Descriptive statistics involve collecting data, organizing data, summarizing data, and presenting data. There are different ways to present data, including charts and tables. It can also be powerful for a summary to be just a numerical value. For example, April 2020 headlines mention US unemployment claims were about 17 million people in three weeks."
  },
  {
    "objectID": "descriptive-and-inferential.html#inferential-statistics",
    "href": "descriptive-and-inferential.html#inferential-statistics",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "3.2 Inferential Statistics",
    "text": "3.2 Inferential Statistics\nStatistical techniques used primarily to draw conclusions about populations are called inferential statistics.\nAn inference is a decision based on samples drawn from populations. Inferential statistics uses probability, which is the chance of an event occurring. For example, the Congressional Budget Office expects the unemployment rate will be 9 percent at the end of 20211. Can you tell why this is an inference rather than a description? We are currently in 2020 so referring to a year in the future is a good indicator we have inferential information. The words “will be” instead of “are” can also be a tip off we are dealing with an inferential statement. (Note - we will try to use other examples but with a pandemic going on it is difficult.)"
  },
  {
    "objectID": "descriptive-and-inferential.html#examples",
    "href": "descriptive-and-inferential.html#examples",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "3.3 Examples",
    "text": "3.3 Examples\nLet’s take a look at some examples and decide if our statements are descriptive or inferential.\n\nExample 3.1 (Left Handed People)  \n\nAbout 10% of people are left-handed.\nIs this descriptive or inferential?\nSolution:\nThis is descriptive. It is a summary.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.2 (Instagram)  \n\n9 out of 10 students in a certain major use Instagram.\nIs this descriptive or inferential?\nSolution:\nThis is descriptive. It is a summary. Which majors do you think are most likely to use Instagram? Please let us know!\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.3 (Bubble Tea)  \n\nDrinking bubble tea can lower cholesterol levels by 1%.\nIs this descriptive or inferential?\nSolution:\nThis is inferential. It is a prediction.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nOne of the authors is obsessed with bubble tea and made this statistic up! That’s a reason why statistics can be powerful and dangerous. Someone may find my false inferential statement and use it as a fact. We will talk about the misuse of statistics soon but please be on the lookout for sources when you are given any data or statements!\n\nExample 3.4 (Median Household Income:)  \n\nAccording to a Census, the US median household income is $63,1792.\nIs this descriptive or inferential?\nSolution:\nThis is descriptive. It is a summary.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.5 (Harvard Class of 2024)  \n\n40,246 prospective students applied to the Harvard Class of 2024.\nIs this descriptive or inferential?\nSolution:\nThis is descriptive. It is a summary.\nDid this one trick you because of a future year? It is descriptive because the class of 2024 enters four years prior to this date and applies months earlier than that!\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.6 (New Courses at FIT)  \n\nIn the year 2030, about 45 new courses will be offered at FIT.\nIs this descriptive or inferential?\nSolution:\nThis is inferential. It is a prediction; we cannot know for sure how many courses will be approved in the next couple years. We hope to have a few in our department!\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nNote that we should usually use the word \"about\" because we cannot retrieve information from every single person in the US or even every single person at FIT! We are using samples of our target population to represent the entire group. If you notice there are two cases in the examples above where we do not use “about” and supposedly have the total population. For applications at a university this does seem reasonable to achieve! For the US Census, we truly want the information to represent the entire population."
  },
  {
    "objectID": "descriptive-and-inferential.html#more-about-inferential-statistics",
    "href": "descriptive-and-inferential.html#more-about-inferential-statistics",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "3.4 More About Inferential Statistics",
    "text": "3.4 More About Inferential Statistics\nLet's look more at inferential statistics. We take data values (called the sample) to make inferences (draw conclusions) about an entire group we're interested in (called the population). After we analyze collected sample data, we reach a conclusion.\nHere is an example:\n\nExample 3.7 (Average Height of Females)  \n\nBased on a random sample of 100 females 18 years or older in New York City, we believe that the average height of all females 18 year or older in New York City is 64 inches with a maximum error of 3 inches. We are 90% confident of this.\nIs this descriptive or inferential?\nSolution:\nThis is inferential.\nHere we are using the data values from our sample (the 100 New York City females) to estimate the average height of the entire population of females in New York City. We get this estimate by doing a calculation based on the data values from the sample. It should be mentioned that we do not find out the height of every single female 18 or older in NYC! Rather, we can only estimate the average and talk about how certain we are of our estimate. Again, we draw conclusions about a certain population based on our specific sample.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "descriptive-and-inferential.html#more-examples",
    "href": "descriptive-and-inferential.html#more-examples",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "3.5 More Examples",
    "text": "3.5 More Examples\nWhy don't you try to answer the following for extra practice in determining whether descriptive or inferential statistics have been used:\nOnce you're done scroll down for the answers!\n\nExample 3.8 (Average Life Expectancy)  \n\nThe average life expectancy in (the) Netherlands is 81.6 years.\nIs this descriptive or inferential?\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.9 (Potassium Lowers Blood Pressure)  \n\nA diet high in potassium will lower blood pressure.\nIs this descriptive or inferential?\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.10 (Bubble Tea Budget)  \n\nThe total amount of money a household spent on Bubble Tea in one week was $35.40. One of the author’s statistics and by the entire household, it is just me (my partner and kids do not drink it).\nIs this descriptive or inferential?\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 3.11 (Number of High School Students)  \n\nIn 2033, the number of high school students will be 3.6 million.\nIs this descriptive or inferential?\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nHere are the solutions:\n\nAverage Life Expectancy - descriptive\nPotassium Lowers Blood Pressure - inferential\nBubble Tea Budget - descriptive\nNumber of High School Students - inferential"
  },
  {
    "objectID": "descriptive-and-inferential.html#footnotes",
    "href": "descriptive-and-inferential.html#footnotes",
    "title": "3  Descriptive and Inferential Statistics",
    "section": "",
    "text": "https://www.cbo.gov/publication/56314↩︎\nhttps://www.census.gov/library/stories/2019/09/us-median-household-income-not-significantly-different-from-2017.html↩︎"
  },
  {
    "objectID": "population-and-sample.html#population",
    "href": "population-and-sample.html#population",
    "title": "4  Population and Sample",
    "section": "4.1 Population",
    "text": "4.1 Population\n\nA population is any precisely defined collection of people or things we want to study.\n\nThe population is what you want to know about. Its the entire group that is the focus of your interest.\nUsually it is a big group, like all voters, or all customers, or all department stores.\nAnd its the entire group you are trying to study. Its not just part of the group you want to study. Its the whole group you want understand!\nHere are some examples\n\nExample 4.1 (Populations)  \n\n\nAll customers for an online ecommerce site\nAll Nordstrom stores in the United States\nAll twitter posts that mention \"Macy's\"\nAll college students that own iphones\n\nThese are all entire groups you might want to study. In each case this is the ideal group you want to completely understand.\nThese are populations.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "population-and-sample.html#sample",
    "href": "population-and-sample.html#sample",
    "title": "4  Population and Sample",
    "section": "4.2 Sample",
    "text": "4.2 Sample\n\nA sample is part of a population you collect data from.\n\nThe sample is smaller than the whole population. But it is taken from the population and corresponds to data that we do collect.\nSome simple examples:\n\npopulation: all voters, sample: data from 100 voters\npopulation: all customers, sample: data from 1000 customers\npopulation: all department stores, sample: data from 50 stores\n\nIn each case a sample corresponds to the actual data you do collect. It usually is not possible to collect data from everyone in your population. Of course you would like to do that. But most of the time we do not have the resources to gather information about every single member of a population.\nSo we study a sample in order to understand the population\nThis is the key idea in inferential statistics, which we will talk about soon.\nHere are some examples of samples using the populations from the last example.\n\nExample 4.2 (Samples)  \n\n\n\n\n\n\n\n\nPopulation\nSample\n\n\n\n\nAll customers for an online ecommerce site\n50 customers from that ecommerce site\n\n\nAll Nordstrom stores in US\nAll Nordstrom stores in tri-state area\n\n\nAll twitter posts mentioning \"Macy's\"\n100 twitter posts mentioning \"Macy's\"\n\n\nAll college students that own iphones\nAll students in one FIT class that own iphones\n\n\n\nThe right column above are all samples.\nThey correspond to data you did collect from the populations in the left column.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nNote that any part of the population you do not collect data from is not in your sample. So anyone you try to collect data from but don't is not part of your sample.\nFor example if you send out 1000 emails to customers of the online ecommerce site, but you only get 50 customers that respond, then the 950 customers that you did not collect data from are not part of your sample.\n\nA sample corresponds only to data you do collect, not any data you try to collect but are unable to\n\nThat means non-responses are not part of the sample. Only data you collect.\nMany of you have heard about a census. A census is a study that attempts to collect data on the entire population. Conducting a census is rarely feasible. The 2020 census was recently due so hopefully you all have experience with a census and every, single household filled it out. Can you say with certainty that every household filled out the census? I don’t think we can. That’s why we usually take samples. (Did you watch the series, “Who Do You Think You Are?” They tend to look at a census to find relatives.)\nLet’s see an example of something about a population we might be interested in:\n\nExample 4.3 (Population and Sample)  \n\nSuppose we wished to estimate the average amount spent on clothes in 2019 for women over the age of 18 living in Long Island. We send out 100 emails about this, and get back 34 answers. As a result we take the average of the 34 responses to get an estimate of what we want.\n\nWhat is the population?\nWhat is the sample?\n\nIn this case, the population would be all Long Island women over the age of 18. We would like to get the amount spent for every one of the women in our population, and then we would take the average of that to get what we want.\nBut instead, we settle for a sample. How big is the sample?\nThe sample is the 34 women we hear back from. It does not include any of the non-responses out of the 100 emails we sent. Only those that responded.\nSo the sample size is \\(n=34\\) in this case.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "population-and-sample.html#population-mean-vs-sample-mean",
    "href": "population-and-sample.html#population-mean-vs-sample-mean",
    "title": "4  Population and Sample",
    "section": "4.3 Population Mean vs Sample Mean",
    "text": "4.3 Population Mean vs Sample Mean\nPopulation Mean\nIn the example above notice that we would like to do a calculation involving the data from the whole population. We would like to average the amounts spent on clothing from all women from Long Island. That is the average we really want.\nThe average over all the population is called a population mean and the symbol for it is \\(\\mu\\) (the greek letter \"mu\").\n\n\\(\\mu\\) is the symbol for population mean\n\nIdeally we want this value.\nSample Mean\nBut in fact we have to settle for a different average, we have to settle for the average over all the amounts spent in our sample, which is the 34 amounts we got back from the women in our sample.\nThis average over the sample is called a sample mean and the symbol for it is \\(\\bar x\\) (called \"x bar\").\n\n\\(\\bar x\\) is the symbol for sample mean\n\nRealistically all we can expect to get is this value.\nSample Mean Estimates the Population Mean\nWe hope that the sample mean is close to the population mean so that we can use the sample mean to estimate the population mean.\n\nThe sample mean \\(\\bar x\\) is an estimate for population mean \\(\\mu\\)\n\nHow good is the estimate? That depends…\nIt depends on things like the sample size, whether the sample is a random sample and represents the population well. We will discuss these things later.\nBut keep in mind that fundamental idea behind inferential statistics is to estimate something about the population from a sample.\nIn the next chapter we will look at more of this idea."
  },
  {
    "objectID": "parameter-and-statistic.html#parameter",
    "href": "parameter-and-statistic.html#parameter",
    "title": "5  Parameter and Statistic",
    "section": "5.1 Parameter",
    "text": "5.1 Parameter\n\nA parameter is a number that describes a property of the population\n\nA parameter is a number we are interested in knowing about the population.\nWe have already seen one example: a population mean (\\(\\mu\\)) is an example of a parameter.\nParameters are computed by using all the data in the population.\nFor example the population mean (\\(\\mu\\)) uses every data value in the population and computes the mean of all that data.\nOf course parameters we almost never have exactly."
  },
  {
    "objectID": "parameter-and-statistic.html#statistic",
    "href": "parameter-and-statistic.html#statistic",
    "title": "5  Parameter and Statistic",
    "section": "5.2 Statistic",
    "text": "5.2 Statistic\n\nA statistic is a number that describes the same property as above but is computed from the sample\n\nA statistic is a number we are interested in but it comes from using only data in the sample, not the whole population.\nWe have already seen one example: a sample mean (\\(\\bar x\\)) is an example of a statistic.\nStatistics are computed by using just the data in the sample.\nFor example the sample mean (\\(\\bar x\\)) uses just the data values in the sample and computes the mean from just that data.\nTIP: It helps to remember p with p and s with s. Parameter with the population and a statistic is with the sample\nI bet you are familiar with hearing the term \"statistic\" with reports. Statistics are the numbers that reports cite when they are published.\nThis is because it is difficult to get parameters since you need data from the whole population.\n\nParameters are difficult to compute directly\nStatistics are easier to compute\n\nIt is much easier to use a sample to compute a statistic, then use that statistic to estimate the parameter of interest than it is to try to compute the parameter directly."
  },
  {
    "objectID": "parameter-and-statistic.html#examples-of-parameter-and-statistic",
    "href": "parameter-and-statistic.html#examples-of-parameter-and-statistic",
    "title": "5  Parameter and Statistic",
    "section": "5.3 Examples of Parameter and Statistic",
    "text": "5.3 Examples of Parameter and Statistic\n\nExample 5.1 (Population and Sample Mean - Amount Spent)  \n\nSuppose we wished to estimate the mean amount spent on clothes in 2019 for women over the age of 18 living in Long Island. We send out 100 emails about this, and get back 34 answers. As a result we take the mean of the 34 responses to get an estimate of what we want. Suppose that sample mean of the 34 responses is $2100.\n\nWhat is the parameter?\nWhat is the statistic?\n\nThe population is women over 18 living in Long Island.\nThe parameter is the mean amount all women living in Long Island spent on clothing in 2019. This is the population mean and the symbol for it is \\(\\mu\\). We don't know the value exactly since it is hard to get data from the whole population.\nThe sample is the 34 women that responded to our email.\nThe statistic is the mean amount the 34 women in the sample spent on clothing in 2019. This is the sample mean and the symbol for it is \\(\\bar x\\). We do know this exactly since we computed it from our sample of 34. It was $2100.\n\\[\n\\bar x = 2100\n\\]\nThis example shows you typically have the statistic, but you don't have the parameter.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nThis example shows:\n\n\n\n\n\n\n\n\n\n\nwhat\nsymbol\nwhen to use\n\n\n\n\npopulation mean\nparameter\n\\(\\mu\\)\nfor mean of entire population\n\n\nsample mean\nstatistic\n\\(\\bar x\\)\nfor mean of sample\n\n\n\nHopefully the statistic will allow us to estimate the parameter. We will talk about this later on.\n\nExample 5.2 (Instagram Influencer Poll)  \n\nAn NYC food instagram influencer posted a poll about the best pizza places. After a heated debate, they asked their NYC followers to call a number and say the name of which restaurant they thought had the best pizza (charge of $1 per vote). It turned out that 68% of callers agreed with the influencer’s choice.\n\nWhat is the population of interest?\nWhat is the sample used to study that population?\n\nIn this case, the desired population would be all NYC followers of this influencer.\nThe sample consists of any person that called to leave a vote.\n\nWhat is the parameter of interest?\nWhat is the statistic?\n\nThe parameter is the proportion of all NYC followers that agreed with the infulencer.\nThe statistic is the 68% (computed from the sample) that agreed with the influencer.\n\nDo you think that 68% is an accurate reflection of all NYC followers of this influencer? If not, identify some of the flaws in the sampling method.\n\nThis is asking if the statistic is a good estimate of the parameter.\nI do not think this was an accurate reflection of all their NYC followers. Big Nope! Do you think all their NYC followers would actually spend money and also use their time to call up and voice a response to a survey? Would you do that?\nAnytime you require people to pay to vote in a call-in poll you are likely only to get the people that feel most strongly about it. This may not be representative.\nAlso, maybe there are some non-New Yorkers who follow this influencer and felt super strongly about their favorite pizza place when they visited. Mmm now I want pizza. (What’s your favorite place for pizza in NYC? Tell us!)\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 5.3 (Population and Sample Proportion - Tiktok Users)  \n\nSuppose we wanted to find out what percent of college students have posted on tiktok. Suppose we polled 120 students and found out that 78 of those have posted on tiktok.\n\nWhat is the population of interest?\nWhat is the sample?\nWhat is the parameter?\nWhat is the statistic?\n\nThe population is \"college\" students.\nThe sample is the 120 students that we collected data from in our poll.\nThe parameter we are interested in is the proportion of all students that have posted on tiktok.\nWe will use the symbol \\(p\\) to stand for population proportion. In this case we do not know the value exactly.\nThe statistic is the proportion of the sample that have posted on tiktok.\nWe will use the symbol \\(\\hat p\\) to stand for sample proportion. In this case we do know the value of this exactly:\n\\[\n\\hat p = \\frac{78}{120} = .65\n\\]\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nThis example shows:\n\n\n\n\n\n\n\n\n\n\nwhat\nsymbol\nwhen to use\n\n\n\n\npopulation proportion\nparameter\n\\(p\\)\nfor proportion of entire population\n\n\nsample proportion\nstatistic\n\\(\\hat p\\)\nfor proportion of sample\n\n\n\nIn summary, we gather data from a sample (usually a small number of data values) to infer things about a population (usually a large number of data values).\nThink about how to get a representative sample of a population at school. For example, if we want to get information on all the students at FIT we cannot just ask the first 20 people leaving one of the buildings. This would not be a good sample.\nWhenever you hear about a statistic in the news we want you to think about this and what the sample is… and other things too, which we will discuss more in this book!"
  },
  {
    "objectID": "variables.html#is-it-a-variable",
    "href": "variables.html#is-it-a-variable",
    "title": "6  Variables",
    "section": "6.1 Is It a Variable?",
    "text": "6.1 Is It a Variable?\nWhich of the following are variables that can be measured on those observational units?\n\nHair color\nWhether or not a student has black hair\nInstructor’s age\nNumber of students with purple hair\nHeight\nHeight of the shortest student in your class\nZip code of hometown\n\nYou just need to ask yourself if each of these is something that varies from student to student.\n\nExample 6.1 (Hair Color)  \n\nImagine you make a list of all students and record for each their hair color.\nFor example you might get this:\n\nStudent 1: brown\nStudent 2: black\nStudent 3: purple\nStudent 4: brown ...\n\nDoes this vary from student to student? Yes. That means it is a variable.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 6.2 (Whether or Not A Student Has Black Hair)  \n\nImagine you make a list of all students and record for each whether or not the student has black hair.\nFor example you might get this:\n\nStudent 1: True\nStudent 2: True\nStudent 3: False\nStudent 4: False ...\n\nDoes this vary from student to student? Yes. That means it is a variable.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\n\nExample 6.3 (Instructor’s Age)  \n\nWhat about if you record for each student what the instructor’s age is?\nLet’s pretend the instructor is 33 and that the instructor told the students this so that they all know.\nImagine you make a list of all students and record for each their instructor’s age.\n\nStudent 1: 33\nStudent 2: 33\nStudent 3: 33\nStudent 4: 33 ...\n\nDoes this vary from student to student? No\nThe instructor’s age for each student is the same,\nThis is because everyone in the class has the same teacher so everyone will give the same value.\nThis means it is not a variable.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nSo here we see something very important.\nSomething that does not vary from observational unit to observational unit is NOT a variable.\nIt has to vary and be different for different students to be a variable.\nNow some students might have the same value (like lots of students have black hair) but if you have the same thing from all your observational units then it is not a variable.\n\nExample 6.4 (Number of Students with Purple Hair)  \n\nFor this one, lets pretend there is 1 student in the class with purple hair and everyone can see them and there is no argument about color.\nImagine you make a list of all students and record their answer to the question \"Number of students with purple hair?\"\n\nStudent 1: 1\nStudent 2: 1\nStudent 3: 1\nStudent 4: 1 ...\n\nDoes this vary from student to student? No\nThis is not something that varies from student-to-student.\nThis means it is not a variable.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nThis is an example of something that is a sum or a total over all the students. Its a property of the whole class of students and not just each individual student.\nSo it really doesn’t even make sense to try to attribute this to each student. It is a property of the aggregate of all the students.\nWe will see that sometimes numbers that summarize the aggregate or whole population or sample are not variables.\n\nImagine you make a list of all students and record their data.\n\nStudent 1: 177 cm\nStudent 2: 162 cm\nStudent 3: 159 cm\nStudent 4: 168 cm ...\n\nThis means it is a variable.\n\n\nExample 6.5 (Height of shortest student)  \n\nFor this one, lets pretend the shortest student is 159 cm.\nImagine you make a list of all students and record their answer to the question \"height of shortest student?\":\n\nStudent 1: 159 cm\nStudent 2: 159 cm\nStudent 3: 159 cm\nStudent 4: 159 cm ...\n\nThis means it is a not variable. It does not change.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nThis one is a property of the whole class, and not just each individual student. Its a property of the aggregate and we saw above numbers or properties if the whole sample or population are not variables.\n\nExample 6.6 (Zip Code)  \n\nImagine you make a list of all students and record their zip codes.\n\nStudent 1: 10001\nStudent 2: 08619\nStudent 3: 90210\nStudent 4: 11211 ...\n\nThis means it is a variable.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "types-of-variables.html#quantitative-variables",
    "href": "types-of-variables.html#quantitative-variables",
    "title": "7  Types of Variables",
    "section": "7.1 Quantitative Variables",
    "text": "7.1 Quantitative Variables\nYou can see from the above that some variables have values that are numbers from a numeric scale or measurement.\nHeight is an example of one of these. As you go from student to student in the class the height is given by a different measurement for each student.\n\nVariables whose values are given by numbers that come from a numeric scale are called quantitative.\n\n\nExample 7.1 (Quantitative Variables)  \n\n\nHeight\nAmount a customer spends in a store\nPercentage markup on an item for sale\nA customer’s age\nSales for an item in december\n\nThese are all values that measure something or come from a numeric scale. so they are quantitative variables.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nBut be careful, if a number is just a way to categorize or label something it is not a quantitative variable.\nQuantitative variables have to come from some numeric scale or measurement. And so they are comparable. If you have two different values (like heights) you can say that the bigger value means something. For height it means that person is taller.\nSo let's see some examples of numbers used to just label something:\n\nExample 7.2 (These Are Not Quantitative Variables)  \n\n\nRaffle ticket numbers\nZip codes\nSKUs (stock keeping unit - in retail an item for sale)\n\nRaffle ticket numbers do not measure anything, they just identify the ticket. So they would not be quantitative.\nZip codes look like they are quantitative but they are not. They just identify an area of the postal system.\nSKUs are often just numbers that label an item for sale in a retail situation.\nThese are not quantitative variables.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nWell if the examples above are not quantiative, what are they? Let's see next."
  },
  {
    "objectID": "types-of-variables.html#categorical-variables",
    "href": "types-of-variables.html#categorical-variables",
    "title": "7  Types of Variables",
    "section": "7.2 Categorical Variables",
    "text": "7.2 Categorical Variables\nThen there are some variables that have choices or categories. Like Hair color. The value comes from some set of choices:\n\nblack\nbrown\npurple\nblonde\nwhite …\n\nAs you go from student to student the value of this variable has to be one of these choices and is not described by a number from a scale.\n\nVariables that are given by a set of choices are called categorical\n\n\nExample 7.3 (Categorical Variables)  \n\n\nPolitcal affiliation (conservative, liberal, moderate)\nYear in college (first-year, sophmore, junior, senior)\nType of store(online store vs brick-and-mortar)\nWas an item marked down (Yes or No)\n\nThese are all choices so they are categorical variables.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "types-of-variables.html#binary-variables",
    "href": "types-of-variables.html#binary-variables",
    "title": "7  Types of Variables",
    "section": "7.3 Binary Variables",
    "text": "7.3 Binary Variables\nSome categorical variables are given by just two choices like true or false.\nWhether a student has black hair is a variable with the value true or false.\nAs you go from student to student the value of this variable has to be one of those two choices.\n\nVariables that have just two choices like true/false or yes/no are called binary variables.\n\nNote that binary variables are categorical variables, its just that there are only 2 choices.\nIn the example above type of store was binary and so is was item marked down. These both had just 2 choices."
  },
  {
    "objectID": "types-of-variables.html#other-terms",
    "href": "types-of-variables.html#other-terms",
    "title": "7  Types of Variables",
    "section": "7.4 Other Terms",
    "text": "7.4 Other Terms\nSometimes people call data described by categorical variables qualitative data.\nThey call data described by quantitative variables quantitative data. There are even other terms like nominal, ordinal for qualitative variables and disrete and continuous for quantitative variables. But we will not get into all of those."
  },
  {
    "objectID": "types-of-variables.html#quantitative-or-categorical",
    "href": "types-of-variables.html#quantitative-or-categorical",
    "title": "7  Types of Variables",
    "section": "7.5 Quantitative or Categorical?",
    "text": "7.5 Quantitative or Categorical?\nLet’s look more on these ideas and do an example together. We want to determine if variables for students in this class are quantitative or categorical. If categorical, also mention if it is binary.\n\nExample 7.4 (Type of Variable)  \n\n\nHeight of students?\nTime spent sleeping last night?\nWhether or not the student went to sleep before midnight?\nBirth month?\nNumerical score on a midterm exam?\nWhether or not a student scores at least 85 on the midterm exam?\nDistance from where a student calls home?\nWhether or not a student has a TV?\nHow many email messages a student has sent in the last 24 hours?\nWhether a student has received at least one email message in the last 24 hours?\nThe number of letters in a student’s first name?\nHow many people live in a student’s household?\n\nJust ask yourself for each variable whether it involves a number measurement or a choice (yes/no, true/false, conservative/moderate/liberal).\nIf it involves a number measurement then it is quantitative, and if it is a choice it is categorical.\nIf it is categorical and there are only two choices, then it is called binary as well.\n\nHeight is quantitative.\nTime spent sleeping last night is quantitative.\nWhether or not the student went to sleep before midnight is categorical and binary.\nMonth of birth is categorical.\nNumerical score on a midterm exam is quantitative.\nWhether or not a student scores at least 85 on the midterm exam is categorical and binary.\nDistance from home is quantitative.\nWhether or not the person has a TV is categorical and binary.\nHow many email messages sent in the last 24 hours is quantitative.\nWhether a student has received at least one email message in the last 24 hours is categorical and binary.\nThe number of letters in a student’s first name is quantitative.\nHow many people live in a student’s household is quantitative.\n\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nSo variables will be the things that we will study in statistics. And oftentimes we will want to study more than just one variable of a group or observational unit as well.\n\nExample 7.5 (Identifying Variables)  \n\nA study found that students who did their schoolwork near natural light scored as much as 20 percent higher on exams than other students in the same school. What are variables of interest to us? Are the variables categorical or quantitative data?\nVariables of interest:\n\nWhether or not a student did their schoolwork near natural light\nScore on exams\n\nWhether or not the student did their schoolwork near natural light is categorical since the choices are yes/no. (It is also binary.)\nScores on the exam are quantitative.\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "validity-and-reliability.html#validity",
    "href": "validity-and-reliability.html#validity",
    "title": "8  Validity and Reliability",
    "section": "8.1 Validity",
    "text": "8.1 Validity\nWe need to know what went on during the research process in order to accept the results, whether they are stated in words or shown in graphs. Even if the study has validity, people (especially those in the media) might distort results from data with misleading charts and graphs. (One of us just spent over an hour looking at some pretty awful charts. Oops.) Anyway, let’s talk about validity.\nWe will focus on two types of validity when deciding whether or not we can trust the results from a study: internal validity and external validity.\n\n8.1.1 External Validity\n\nThe ability to get a true representation of the population from a sample is to achieve external validity.\n\nExternal validity is the certainty that the observations in our methods and presence in no way jeopardize our ability to use the random sample as a true representative of the population. We need to make sure we did not influence the results in any way- by the way we collected data or by our presence. We also need to make sure that what we did in a specific place can be generalized to the entire population we wish to study. This means that if we are doing a test in a free clinic, can we generalize to all patients? If we asked students on the 8th Floor in the C building, can we generalize to all FIT students?\n\n\n8.1.2 Internal Validity\n\nInternal validity is the certainty that the observations in our sample are accurate measures of the characteristics we set out to measure.\n\nWe need to make sure that from our sample we obtained HONEST, ACCURATE, and RELIABLE information for internal validity. Imagine we are doing a study about the ages of a certain group. We should be able to get the actual ages. Believe it or not, people many lie about their age. Or, someone may actually forget how old they are (it happens)!\nIn order to make sure we have internal validity we could ask to see driver’s licenses or passports.\n\n\n8.1.3 Examples of Validity\nFor the following two examples, answers are given below.\n\nExample 8.1 (Creating Potions)  \n\nProfessor Snape wanted to know his students’ ability to create potions. So he went over to each student and measured their efforts. Some students may have become nervous and their ability to produce potions could have been influenced by Snape’s presence. (I mean… did you see Neville’s face?!) So, his study may not reflect the actual potion-making ability of the students, because of the violation of ___________ validity.\n\n\n\nExample 8.2 (Gamma Radiation of Cosmic Tesseract)  \n\nDr. Banner and Mr. Stark were studying a cosmic tesseract and its levels of gamma radiation. They decided to gather information of the concentration of gamma radiation in all cosmic cubes and precisely weigh each from their sample. If they were given a faulty scale, then there is a violation of ___________ validity.\n\n\n\nAnswers\nCreating Potions\n\nAnswer: External\nReason: Professor Snape failed to make sure he did not influence the results in any way by his presence. (External validity: We need to make sure we did not influence the results in any way- by the way we collected data or by our presence. )\n\nGamma Radiation of Cosmic Tesseract\n\nAnswer: Internal\nReason: If the scale was faulty then our sample of precise weight did not contain HONEST, ACCURATE and RELIABLE information."
  },
  {
    "objectID": "validity-and-reliability.html#reliability",
    "href": "validity-and-reliability.html#reliability",
    "title": "8  Validity and Reliability",
    "section": "8.2 Reliability",
    "text": "8.2 Reliability\nWe want studies to not just be valid but also reliable.\nReliability is different from validity! A measurement may be valid but not reliable, or reliable but not valid.\n\nReliability is another term for consistency.\n\nFor reliability if the study was done a second time you would get the same results.\nNote that this is different from accuracy. Reliability just means it is consitent. It says nothing about accuracy.\nImagine if we had a colleague bring in a scale to our department at FIT in 2021. A certain mathematics professor decides to change this scale to show the weight but five pounds lighter! If anyone weighs themselves a couple times in one hour, the weight it shows will be reliable since it is the same every time the individual steps on it. It will not be accurate, since it is not reading the actual weight (but five pounds lighter than the true weight).\nWe also want to give an example of a bullseye because that is the most common way to visualize these terms. Seriously… if you google these terms and search images most are going to show bullseyes.\nWhere do you expect points to be on a bullseye if we have both reliability and validity?\nCan you think of what points on a bullseye may look like when the shots are reliable but they would not be valid (so miss the target)?\n\n\n\n\n\n\n\n\nWhat about not reliable but valid?\nAnd not reliable and not valid?"
  },
  {
    "objectID": "dotplots-and-distributions.html#dotplot",
    "href": "dotplots-and-distributions.html#dotplot",
    "title": "9  Dotplots and Distributions",
    "section": "9.1 Dotplot",
    "text": "9.1 Dotplot\nFor example suppose we have the following data set:\n\\[\n6, 8, 8, 9, 5, 6, 8\n\\]\nHere is the dotplot that goes with this:\n\n\n\n\n\n\n\n\n\nYou can see there are:\n\none 5\ntwo 6s\nthree 8s\none 9\n\nDotplots are very good at showing the overall shape of the data. This shape is sometimes called the distribution.\nSo you will hear people speaking about the data and just calling it a \"distribution\"."
  },
  {
    "objectID": "dotplots-and-distributions.html#three-important-properties-of-distributions",
    "href": "dotplots-and-distributions.html#three-important-properties-of-distributions",
    "title": "9  Dotplots and Distributions",
    "section": "9.2 Three Important Properties of Distributions",
    "text": "9.2 Three Important Properties of Distributions\nThree very important properties about distributions:\n\nAre there any peaks?\nHow spread out is the data?\nAre there any outliers?\n\n\n9.2.1 Peaks\nFor the peaks you might have just one or you might have more than one.\nOr you might have none!\nHere is some data that we want to look for peaks for:\n\\[\n12, 11, 7, 2, 4, 4, 9, 12, 5, 3, 14, 12, 4, 13, 10, 13, 12, 4, 3, 7\n\\]\nIf we make a dotplot of this data it looks like this:\n\n\n\n\n\n\n\n\n\nYou might describe this like this:\n\nThe data has two peaks, one at 4 and one at 12\n\nYou might also have a distribution with no peaks. Here is an example of that:\n\\[\n12, 29, 18, 14, 22, 28, 5, 24, 6, 10\n\\]\nIf we make a dotplot of this data it looks like this:\n\n\n\n\n\n\n\n\n\nYou might describe this like this:\n\nThe data has no peaks\n\nSome people describe peaks as \"clusters\", but it is also possible to have clustering without a peak.\nI think it is better to describe \"peaks\" as high points in the distribution and \"clusters\" as data values that are close to each other along the horizontal axis.\nYou can see an example of clusters that are not peaks below.\n\n\n9.2.2 Spread\nFor the spread of the data, one common way to talk about the spread is to look for the \"range\" it has.\nThe range is from the minimum value to the maximum value.\nHere's an example:\n\\[\n30, 29, 22, 26, 32, 32, 23, 28, 20, 28, 37, 35, 29, 36, 34\n\\]\nIf we make a dotplot of this data it looks like this:\n\n\n\n\n\n\n\n\n\nYou might describe this like this:\n\nThe range of this data is from 20 to 37\n\nThe range is one part important part of the spread. But it is not all of the story. You might also look for clusters of data as well.\nHere is another example of some data:\n\\[\n3, 12, 11, 13, 14, 25, 26, 27, 45, 46, 44, 52\n\\]\nIf we make a dotplot of this data it looks like this:\n\n\n\n\n\n\n\n\n\nYou might describe this like this:\n\nThe data is in three clusters, one at about 13, one about 26, and one at 45.\n\nThe range of this data is from 3 to 52, but you would also notice this clustering as well.\n\n\n9.2.3 Outliers\nFinally you might also look for outliers.\nOutliers are data values that are far from the others in the data, and do not look typical. Sometimes outliers are errors in the data collection process. Sometimes they are just unusual values that happened.\nBelow is an example three years of demand data for a product.\nHere are the actual values from the last 36 months for this product:\n\\[\n38, 46, 58, 36, 44, 46, 51, 43, 61, 44, 48, 53, 42, 37, 59, 27, 52, 45, 53, 48, 62, 35, 58, 61, 45, 25, 49, 40, 51, 47, 51, 48, 54, 43, 39, 40\n\\]\nOf course we are interested in whether there is some months where demand was very low or some months where the demand was vary high.\nWe could just look at the numbers above, but it is nice to see this as a graph as well too. So lets look at a dotplot of these values:\n\n\n\n\n\n\n\n\n\nYou might describe this like this:\n\nThe data has a couple of outliers at 25 and 27\n\nMost of the time the demand for this product was roughly between 34 and 54 but there were some outliers. You might be tempted to ask what happened for those months where the demand was 25 or 27.\nAlso there are a couple of clusters of high values as well around 58 and 62.\nThese might not be considered outliers but you would definitely like to understand what is happening there as well."
  },
  {
    "objectID": "barplots.html#market-share",
    "href": "barplots.html#market-share",
    "title": "10  Barplots",
    "section": "10.1 Market Share",
    "text": "10.1 Market Share\nSuppose the following fashion stores having competing products with the following market shares:\n\n\n\n\n\nCompany\nSales\n\n\n\n\nPop Shop\n200000\n\n\nTommy Go Figure\n100000\n\n\nNever 42\n600000\n\n\nCountry Infitters\n300000\n\n\n\n\n\nHere is the barplot that goes with this:\n\n\n\n\n\n\n\n\n\nNow suppose we want the percentage breakdown of these market shares:\n\nFrom Pop Shop:\n\n\\[\n\\frac{200000}{1200000} =\n17\\%\n\\]\n\nFrom Tommy Go Figure:\n\n\\[\n\\frac{100000}{1200000} =\n8\\%\n\\]\n\nFrom Never 42:\n\n\\[\n\\frac{600000}{1200000} =\n50\\%\n\\]\n\nFrom Country Infitters:\n\n\\[\n\\frac{300000}{1200000} =\n25\\%\n\\]\nSo here is the market share by percentage:\n\n\n\n\n\nCompany\nPercent\n\n\n\n\nPop Shop\n17\n\n\nTommy Go Figure\n8\n\n\nNever 42\n50\n\n\nCountry Infitters\n25\n\n\n\n\n\nNow if we make a barplot with percentages this looks like this:\n\nExample 10.1 (Market Share By Percent)  \n\n\n\n\n\n\n\n\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nOf course the graph does not look any different, but it is nice to see the percentage breakdown in the chart easily."
  },
  {
    "objectID": "central-tendencies.html#mean",
    "href": "central-tendencies.html#mean",
    "title": "11  Central Tendencies",
    "section": "11.1 Mean",
    "text": "11.1 Mean\nThe mean is what we also call the average. This is probably the most familiar measurement of central tendency you know. You already use this all the time.\nFor the record we will give a notation and a name:\n\\[\n\\bar x = \\frac{\\sum x}{n}\n\\]\nThe number on the left is called “x bar” and is the sample average or mean. On the right, the sigma sign (Greek letter) stands for summation and the on the right means “sum all the data values” where the x stands for each data value in the sum. After you add all the data values up you divide by n which is the sample size.\n\nSuppose we have the following sample data:\n\\[\n10,6,5,14,6,12\n\\]\nThen we can find the mean of this sample as follows:\n\\[\n\\bar x = \\frac{\\sum x}{n} = \\frac{10+6+5+14+6+12}{n} = 8.83\n\\]"
  },
  {
    "objectID": "central-tendencies.html#median",
    "href": "central-tendencies.html#median",
    "title": "11  Central Tendencies",
    "section": "11.2 Median",
    "text": "11.2 Median\nThe median of a sample is just the value that is in the \"middle\" of the data when you line them up in order from smallest to largest.\nIf you have an odd number of data values you just pick the \"middle\" value:\n\nSuppose we have the following sample data:\n\\[\n2,5,3,1,7\n\\]\nTo find the median of the sample you have to rearrange the data values so they are in order first:\n\\[\n1,2,3,5,7\n\\]\nNow the median is just the “middle” value: \\[\nmedian = 3\n\\]\n\nWhat happens if you have an even number of data values, so that there isn’t one number in the middle?\nIn that case you average together the \"two middle values\":\n\nSuppose you have the data values:\n\\[\n2,5,3,7\n\\]\nTo find the median of the sample you have to rearrange the data values so they are in order first:\n\\[\n1,2,3,7\n\\]\nNow the median is just the average of the two “middle” values:\n\\[\nmedian = \\frac{2+3}{2}=3.5\n\\]\n\nSo the median of a sample is the value right in the middle.\nAn important property of the median is that it \"splits\" the data right in the middle:\n\nThe median has \"half the data above it\" and \"half the data below it\"\n\nRemember the mean is not guaranteed to be \"in the middle\" but the median is."
  },
  {
    "objectID": "central-tendencies.html#mode",
    "href": "central-tendencies.html#mode",
    "title": "11  Central Tendencies",
    "section": "11.3 Mode",
    "text": "11.3 Mode\nFinally the mode of a sample is just the value that occurs most frequently.\n\nConsider the following list of data values: \\[\n12,3,8,7,6,3,15,13,9,5\n\\]\nThen the most frequently occurring value is 3. It occurs twice and all the other values only occur once.\n\\[\nmode = 3\n\\]"
  },
  {
    "objectID": "central-tendencies.html#some-examples",
    "href": "central-tendencies.html#some-examples",
    "title": "11  Central Tendencies",
    "section": "11.4 Some Examples",
    "text": "11.4 Some Examples\n\nConsider the following list of salaries from a company:\n$36,500 $36,950 $37,800 $39,750 $40,000 $258,000\nHmmm…There are 5 salaries all about the same and one really high.\nProbably here the last one is the CEO’s salary.\nWhen you say that the salaries at the company are \"pretty low\", the CEO does a calculation and computes the mean salary:\n\\[\n\\bar x = \\frac{\\sum x}{n} = \\$74,833.33\n\\]\nHe says the average salary is \\(\\$74,833\\) .\nNot too bad by his account!!\nBut wait, that doesn’t seem to tell the whole story. If you find the median of the salaries here you get the following:\n\\[\nmedian = \\frac{37800+39750}{2} = \\$38775\n\\]\nThe median salary is \\(\\$38,775\\)\nThat is very different from the mean:\n\\(\\$74,833\\) vs \\(\\$38,775\\)\nWow!\nNow surely in this case the median is more representative of the “average” salary at the company.\nJust look at the numbers!\nIn this case the median does seem to be better at describing the situation."
  },
  {
    "objectID": "central-tendencies.html#mean-vs-median",
    "href": "central-tendencies.html#mean-vs-median",
    "title": "11  Central Tendencies",
    "section": "11.5 Mean vs Median",
    "text": "11.5 Mean vs Median\nIncome or Wealth\nTalking about income is a good example where we should be careful to use things like median to describe central tendency.\n\nUse median to describe \"average\" salaries or income levels\n\nReal Estate or Property Values\nAnother example is real estate. Usually almost every county has some properties that are very very expensive compared to all the rest. These will weigh on the mean and influence it greatly, so it is better to list property values using things like the median.\n\nUse median to describe \"average\" property or real estate values\n\nSo look for the median property value in a county if you are looking for a place to live."
  },
  {
    "objectID": "measures-of-spread.html#range",
    "href": "measures-of-spread.html#range",
    "title": "12  Measures of Spread",
    "section": "12.1 Range",
    "text": "12.1 Range\nThe range of the data is just the maximum value minus the minimum value. We have already talked about the range earlier when we talked about dotplots. So we just give a simple example\n\nSuppose we have the following sample data:\n\\[\n10,6,5,14,6,12\n\\]\nThen the largest value is 14 and the smallest is 5 so the range of the data is given by:\n\\[\nrange=max-min=14-5=9\n\\tag{12.1}\\]"
  },
  {
    "objectID": "measures-of-spread.html#mean-deviation",
    "href": "measures-of-spread.html#mean-deviation",
    "title": "12  Measures of Spread",
    "section": "12.2 Mean Deviation",
    "text": "12.2 Mean Deviation\nThe mean deviation is just the average distance the data values are from the mean. So in order to find this you would find the mean, then find the distance between the mean and each data value, then average those distances.\nThis deviation shows how you can describe spread as an “average distance from the center”, which is an important concept for describing the spread of data.\n\nSuppose we have the following sample data:\n\\[\n5,8,4,11\n\\]\nThe mean is\n\\[\n\\text{mean}=\\frac{5+8+4+11}{4}=7\n\\tag{12.2}\\]\nSo the distance the data values are from the mean is like this:\n\n\n\ndata value\ndistance from 7 (the mean)\n\n\n5\n2\n\n\n8\n1\n\n\n4\n3\n\n\n11\n4\n\n\n\n\\[\n\\text{mean deviation}=\\frac{2+1+3+4}{4}=2.5\n\\tag{12.3}\\]\nSo we can say on average the distance the data values are from the center 7 is 2.5\n\nHere is a picture for the data from the last example:\n\n\n\n\n\nVisually we can see that some values are more than 2.5 away from 7 and some are less that 2.5.\nSo the mean deviation is a measure of how far on average the data is away from the center, in this case given by the mean."
  },
  {
    "objectID": "measures-of-spread.html#standard-deviation",
    "href": "measures-of-spread.html#standard-deviation",
    "title": "12  Measures of Spread",
    "section": "12.3 Standard Deviation",
    "text": "12.3 Standard Deviation\nThe mean deviation shows the idea of the \"average distance away\" as a description of the spread of the data. The next measure of spread that we look at will be the one we use most frequently. It also is a measure of the \"average distance away\" from the center, but it uses a different way to calculate that distance.\nWe give the formula here for a population:\n\\[\n\\sigma = \\text{standard deviation} = \\sqrt{\\frac{\\sum (x-\\mu)^2}{N}}\n\\tag{12.4}\\]\nwhere \\(\\mu\\) is the mean of the population and \\(N\\) is the population size\nNow we will usually use this formula for a sample and not a population, and for a sample we adjust it a little:\n\\[\ns = \\text{sample standard deviation} = \\sqrt{\\frac{\\sum (x-\\bar x)^2}{n-1}}\n\\tag{12.5}\\]\nwhere \\(s\\) is the sample mean and \\(n\\) is the sample size. Notice that the denominator is \\(n-1\\). That is a little different from the population version above. We won't go into the reasons for it here, but this gives the sample standard deviation better properties if we do this.\n\nWe will NEVER use the formula directly, but always compute with a spreadsheet\n\n\n12.3.1 Calculating Standard Deviation in a Spreadsheet\nSo let’s do an example of a sample standard deviation calculation using a spreadsheet so you can see how that goes:\nSuppose we have this sample data (with sample size \\(n=7\\)):\n\\[\n5,12,13,5,3,9,10\n\\]\nLets enter this into a column in a spreadsheet and find the mean and the sample standard deviation:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n\n\n1\n\ndata\n\n\n\n\n\n\n2\n\n5\nmean\n=AVERAGE(B2:B8)\n\n\n\n\n3\n\n12\nstd dev\n=STDEV(B2:B8)\n\n\n\n\n4\n\n13\n\n\n\n\n\n\n5\n\n5\n\n\n\n\n\n\n6\n\n3\n\n\n\n\n\n\n7\n\n9\n\n\n\n\n\n\n8\n\n10\n\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n\n\nHere is the result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n\n\n1\n\ndata\n\n\n\n\n\n\n2\n\n5\nmean\n8.14\n\n\n\n\n3\n\n12\nstd dev\n3.85\n\n\n\n\n4\n\n13\n\n                         \n\n\n\n\n5\n\n5\n\n\n\n\n\n\n6\n\n3\n\n\n\n\n\n\n7\n\n9\n\n\n\n\n\n\n8\n\n10\n\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n\n\nSo you should always do standard deviation calculations using a spreadsheet. This is the best way.\n\n\n12.3.2 Interpretation of Standard Deviation\nThe way we interpret the results above is this:\nWe say that on average the typical data value is about 3.85 units from the mean 8.14."
  },
  {
    "objectID": "zvalues.html#population-z-value",
    "href": "zvalues.html#population-z-value",
    "title": "13  Z-Values",
    "section": "13.1 Population Z Value",
    "text": "13.1 Population Z Value\nFirst lets look at the population version of it. Suppose you know the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\) for some population. You can find the \\(z\\)-value for any data value \\(x\\) like this:\n\\[\nz =\\frac{x -\\mu}{\\sigma}\n\\tag{13.2}\\]\nLets see some examples of this in action:\n\nExample 13.1 (Find the z-value)  \n\n\nSuppose that \\(x=54\\) for a distribution with mean \\(52\\), standard deviation \\(8\\), find the z-value for the given \\(x\\).\nSolution:\nWe have \\(\\mu=52\\), \\(\\sigma=8\\) and \\(x = 54\\).\nFrom these we can find the value of z as follows:\n\\[\\begin{equation}\nz=\\frac{x-\\mu}{\\sigma}\n=\\frac{54-52}{8}\n=\\frac{2}{8}\n=0.25\n\\end{equation}\\]\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nHere is an example where we find the z-value of an exam score of \\(65\\):\n\nExample 13.2 (Find the z-value for an exam)  \n\n\nSuppose that \\(x=65\\) for a distribution with mean \\(72\\), standard deviation \\(8\\), find the z-value for the given \\(x\\).\nSolution:\nWe have \\(\\mu=72\\), \\(\\sigma=8\\) and \\(x = 65\\).\nFrom these we can find the value of z as follows:\n\\[\\begin{equation}\nz=\\frac{x-\\mu}{\\sigma}\n=\\frac{65-72}{8}\n=\\frac{-7}{8}\n=-0.88\n\\end{equation}\\]\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nThese two examples show us something about the sign of a z-value.\nPositive and negative \\(z\\)-values have a very nice interpretation:\n\nIf \\(z\\) is positive that tells us that \\(x\\) is above the mean \\(\\mu\\).\nIf \\(z\\) is negative that tells us that \\(x\\) is below the mean \\(\\mu\\).\n\nIn fact the size of the z-value tells even more:\n\nthe \\(z\\) is the number of standard deviations away from the mean\n\nHere is a table that shows how the number of standard deviations matches the z-score:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(z\\)\n\\(-3\\)\n\\(-2\\)\n\\(-1\\)\n\\(0\\)\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\n\n\n\n\\(x\\)\n\\(\\mu-3\\sigma\\)\n\\(\\mu-2\\sigma\\)\n\\(\\mu-\\sigma\\)\n\\(\\mu\\)\n\\(\\mu+\\sigma\\)\n\\(\\mu+2\\sigma\\)\n\\(\\mu+3\\sigma\\)\n\n\n\nSo when we add another \\(\\sigma\\) to the x-value, that corresponds to increasing the z-value by 1:\n\nExample 13.3 (Number of Standard Deviations)  \n\nSuppose that the mean is \\(25\\) and standard deviation is \\(3\\).\nMake the table that shows the x-values for the z-values -3,-2,-1,0,1,2,3:\n\n\n\n\\(z\\)\n\\(-3\\)\n\\(-2\\)\n\\(-1\\)\n\\(0\\)\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\n\n\n\n\\(x\\)\n\\(16\\)\n\\(19\\)\n\\(22\\)\n\\(25\\)\n\\(28\\)\n\\(31\\)\n\\(34\\)\n\n\n\nSo each 3 units in x (1 standard deviation) equates to 1 unit in z\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "zvalues.html#comparing-different-situations",
    "href": "zvalues.html#comparing-different-situations",
    "title": "13  Z-Values",
    "section": "13.2 Comparing Different Situations",
    "text": "13.2 Comparing Different Situations\nUsing z-scores can also allow you to compare different situations that look like you might not be able to compare otherwise.\n\nExample 13.4 (Who Did Better?)  \n\nSuppose you and your friend take different exams in different classes:\n\nyou get 75 on test 1 with a mean of 71 and standard deviation of 3\nyou get 80 on test 2 with a mean of 50 and standard deviation of 12\n\nWho did better?\nSolution:\nYour score: \\[\nx=75\n\\]\nClass mean and standard deviation: \\[\n\\mu=71\n\\] \\[\n\\sigma=3\n\\]\nFriend’s score: \\[\nx=82\n\\]\nClass mean and standard deviation in friend’s class: \\[\n\\mu=81\n\\] \\[\n\\sigma=5\n\\]\nWho did better?\nOn the one hand it looks like your friend got a higher score. But look at the means! Your friend is not that far above the mean in their class, but you are a lot farther above the mean from your class.\nIn this case you can even the playing field by using z-scores and comparing those.\nYour z-score is:\n\\[\nz = \\frac{x-\\mu}{\\sigma}=\\frac{75-71}{3}=1.3\n\\]\nYour friend’s z-score is:\n\\[\nz = \\frac{x-\\mu}{\\sigma}=\\frac{82-81}{5}=.2\n\\]\nSince your z-score is higher, you did better compared to your class, than your friend did compared to their class\n\n\\[ \\tag*{$\\blacksquare$} \\]"
  },
  {
    "objectID": "zvalues.html#sample-z-value",
    "href": "zvalues.html#sample-z-value",
    "title": "13  Z-Values",
    "section": "13.3 Sample Z Value",
    "text": "13.3 Sample Z Value\nThis time the equation looks like this:\n\\[\nz =\\frac{x-\\bar x}{s}\n\\tag{13.3}\\]\nwhere \\(\\bar x\\) is the sample mean and \\(s\\) is the sample standard deviation. Use this formula if you have just sample data to work with and do not know the population mean and population standard deviation.\nThe meaning of it is very similar to the population z-value version above."
  },
  {
    "objectID": "zvalues.html#finding-the-x-value",
    "href": "zvalues.html#finding-the-x-value",
    "title": "13  Z-Values",
    "section": "13.4 Finding the X Value",
    "text": "13.4 Finding the X Value\nIf we do some re-arranging of the equation at the beginning of the secxtion, we can get \\(x\\) in terms of \\(\\mu\\) and \\(\\sigma\\):\n\\[\nx =\\mu + z\\sigma\n\\tag{13.4}\\]\nThis is a version of using the \\(z\\)-value formula backwards.\nThis calculation turns up as well (in what is called \"backwards\" problems) and we can see this is exactly what we used when we made the correspondence between z-values and x-values above"
  },
  {
    "objectID": "standard-normal-curve.html#left-tail-areas",
    "href": "standard-normal-curve.html#left-tail-areas",
    "title": "14  Standard Normal Curve",
    "section": "14.1 Left Tail Areas",
    "text": "14.1 Left Tail Areas\nHere are some examples of various left tail areas:\n\n\n\n\n\n\n\n\n\n\nThe first left tail area has a z-value of -1.43\nThe second left tail area has a z-value of 2.01\nThe third left tail area has a z-value of 0.18\n\nClearly the farther the z-value is to the right, the larger the left tail area.\n\nThe first left tail area is certainly less than 50%, something like 15%\nThe second left tail area is more than 50%, looks like around 90% actually.\nThe third left tail area is a little more than 50%\n\nSo you can see here that every z-value has a left tail area that goes with it."
  },
  {
    "objectID": "standard-normal-curve.html#right-tail-areas",
    "href": "standard-normal-curve.html#right-tail-areas",
    "title": "14  Standard Normal Curve",
    "section": "14.2 Right Tail Areas",
    "text": "14.2 Right Tail Areas\nHere are some examples of various right tail areas:\n\n\n\n\n\n\n\n\n\n\nThe first right tail area has a z-value of -1.03\nThe second left tail area has a z-value of 0.31\nThe third left tail area has a z-value of 1.89\n\nClearly the farther the z-value is to the right, the smaller the right tail area.\n\nThe first right tail area is more than 50%\nThe second right tail area is slightly less than 50%\nThe third right tail area is very small like around 10%"
  },
  {
    "objectID": "standard-normal-curve.html#area-between",
    "href": "standard-normal-curve.html#area-between",
    "title": "14  Standard Normal Curve",
    "section": "14.3 Area Between",
    "text": "14.3 Area Between\n\n\n\n\n\n\n\n\n\n\nThe first area between looks like it might be about 25%\nThe second area between looks like it might be around 80%\nThe third area between looks like it might be around 70%"
  },
  {
    "objectID": "standard-normal-table.html",
    "href": "standard-normal-table.html",
    "title": "15  Standard Normal Table",
    "section": "",
    "text": "This section shows how to use the standard normal table to find left tail areas. We will be finding the areas for examples like these.\nThe standard normal table (z-table) we use is in Appendix A This table contains only left tail areas in it, so in this section we concentrate on showing examples of finding left tail area using the table.\nIf you have a right tail area or area between that you need to find, you will have to use some tricks to find the area you want by using the table and some left tail area. In Standard Normal Areas we see how to do that.\nSo here are a few examples of finding left tail areas using the table:\n\nExample 15.1 (Left tail area for \\(z=-1.25\\))  \n\n\nFind the left tail area when \\(z=-1.25\\). Use the standard normal table.\nSolution:\nWe have \\(z=-1.25\\).\nBelow is a picture of the area. We want to know how big the shaded area is. In particular if the whole area under the curve is 100%, how big is the shaded part?\n\n\n\n\n\n\n\n\n\nWe start by going to the row that has \\(z=-1.2\\) and then we go over to the column that is \\(.05\\). The left tail area is where the row and column meet.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n\n\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n\n\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n\n\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n\n\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n\n\n\n\n\n\n\nSo we have this: \\[\\begin{equation}\n\\text{left tail area} =0.1056\n\\end{equation}\\]\nRounded to the nearest percent this is \\(11\\)%. The shaded region represents about \\(11\\)% of the entire area.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\n\nExample 15.2 (Left tail area for \\(z=1.32\\))  \n\n\nFind the left tail area when \\(z=1.32\\). Use the standard normal table.\nSolution:\nWe have \\(z=1.32\\).\nBelow is a picture of the area. We want to know how big the shaded area is. In particular if the whole area under the curve is 100%, how big is the shaded part?\n\n\n\n\n\n\n\n\n\nWe start by going to the row that has \\(z=1.3\\) and then we go over to the column that is \\(.02\\). The left tail area is where the row and column meet.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n\n\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n\n\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n\n\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n\n\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n\n\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n\n\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n\n\n\n\n\n\n\nSo we have this: \\[\\begin{equation}\n\\text{left tail area} =0.9066\n\\end{equation}\\]\nRounded to the nearest percent this is \\(91\\)%. The shaded region represents about \\(91\\)% of the entire area.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\n\nExample 15.3 (Left tail area for \\(z=0.07\\))  \n\n\nFind the left tail area when \\(z=0.07\\). Use the standard normal table.\nSolution:\nWe have \\(z=0.07\\).\nBelow is a picture of the area. We want to know how big the shaded area is. In particular if the whole area under the curve is 100%, how big is the shaded part?\n\n\n\n\n\n\n\n\n\nWe start by going to the row that has \\(z=0.0\\) and then we go over to the column that is \\(.07\\). The left tail area is where the row and column meet.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n\n\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n\n\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\n\n\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n\n\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n\n\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n\n\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n\n\n\n\n\n\n\nSo we have this: \\[\\begin{equation}\n\\text{left tail area} =0.5279\n\\end{equation}\\]\nRounded to the nearest percent this is \\(53\\)%. The shaded region represents about \\(53\\)% of the entire area.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-areas.html#standard-normal-left-tail-areas",
    "href": "standard-normal-areas.html#standard-normal-left-tail-areas",
    "title": "16  Standard Normal Areas",
    "section": "16.1 Standard Normal Left Tail Areas",
    "text": "16.1 Standard Normal Left Tail Areas\nThe first examples here are for left tail areas. We actually already saw how to do this in Standard Normal Table by looking up the z-value and reading off the left tail area directly in the table, but it is worth doing one more example since it is so important.\nHere is a problem with the z-value is positive:\n\nExample 16.1 (Find left tail area when \\(z=1.52\\))  \n\n\nFind the left tail area when \\(z=1.52\\).\nSolution:\nWe have \\(z = 1.52\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z=1.52\\)\nIf we look up the area in the standard normal z-table using \\(z=1.52\\) we go to the row that has 1.5 and then to the column that contains .02 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n\n\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n\n\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.9357\n\\end{equation}\\]\nRounded to the nearest percent this is 94%. This means that the shaded area corresponds to 94% of the entire data.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-areas.html#standard-normal-right-tail-areas",
    "href": "standard-normal-areas.html#standard-normal-right-tail-areas",
    "title": "16  Standard Normal Areas",
    "section": "16.2 Standard Normal Right Tail Areas",
    "text": "16.2 Standard Normal Right Tail Areas\nNext lets take a look at finding a right tail area. Since our table only uses left tail areas we need a trick. This trick is sometimes called the 1 minus trick.\nIt relies on this fact:\n\\[\n\\text{right tail area} + \\text{left tail area} = 1.0\n\\tag{16.1}\\]\nThat is any right tail and its corresponding left tail add up to 100%.\nSo for example below the right tail is 0.06 and the left tail is 0.94 and these add up to 1.0\n\n\n\n\n\n\n\n\n\nSo when we want to find the right tail area for some situation we can just find the left tail area and then subtract. Here are some examples.\n\nExample 16.2 (Find right tail area when \\(z=-1.32\\))  \n\n\nFind the right tail area when \\(z=-1.32\\).\nSolution:\nHere is the picture of the area we want. This area is called a “right tail area”:\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the right of \\(z=-1.32\\) and underneath the standard normal curve.\nSince the standard normal table only has “left tail” areas in it, we cannot look up the area we want directly. But if we look up the left tail area in the z-table for \\(z=-1.32\\), we can then subtract that from 1.0 to get the area that we want.\nNow to find the left tail area we need using standard normal z-table using \\(z=-1.32\\) we go to the row that has -1.3 and then to the column that contains .02 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n\n\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n\n\n\n\n\nSo the left tail area is 0.0934. We use this to find the right tail area now:\n\\[\\begin{equation}\n\\text{right tail area}=1.0 - \\text{left tail area} =1.0 - 0.0934 = 0.9066\n\\end{equation}\\]\nRounded to the nearest percent this right tail area is 91%.\nThis means that the shaded area corresponds to 91% of the entire data.\nAnother way to say it is that 91% of the data falls to the right of \\(z=-1.32\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nAnother example:\n\nExample 16.3 (Find right tail area when \\(z=0.52\\))  \n\n\nFind the right tail area when \\(z=0.52\\).\nSolution:\nHere is the picture of the area we want. This area is called a “right tail area”:\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the right of \\(z=0.52\\) and underneath the standard normal curve.\nSince the standard normal table only has “left tail” areas in it, we cannot look up the area we want directly. But if we look up the left tail area in the z-table for \\(z=0.52\\), we can then subtract that from 1.0 to get the area that we want.\nNow to find the left tail area we need using standard normal z-table using \\(z=0.52\\) we go to the row that has 0.5 and then to the column that contains .02 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n\n\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n\n\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n\n\n\n\n\n\n\nSo the left tail area is 0.6985. We use this to find the right tail area now:\n\\[\\begin{equation}\n\\text{right tail area}=1.0 - \\text{left tail area} =1.0 - 0.6985 = 0.3015\n\\end{equation}\\]\nRounded to the nearest percent this right tail area is 30%.\nThis means that the shaded area corresponds to 30% of the entire data.\nAnother way to say it is that 30% of the data falls to the right of \\(z=0.52\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-areas.html#standard-normal-area-between",
    "href": "standard-normal-areas.html#standard-normal-area-between",
    "title": "16  Standard Normal Areas",
    "section": "16.3 Standard Normal Area Between Two Z Values",
    "text": "16.3 Standard Normal Area Between Two Z Values\nFinding the area between involves a trick as well.\nFind Area Between Z Values\n\nYou look up the left tail area to the “upper z” (the one farthest to the right).\nThen you look up the left tail area to the “lower z” (the one farthest to the left).\nThen you subtract those two areas to get the area between.\n\nBe sure to subtract these the right way. If you subtract them backwards your answer will turn out negative. Since areas cannot be negative, you will know you made a mistake.\nOkay here are some examples of finding the area between two z-values.\n\nExample 16.4 (Find area between \\(z_1=0.52\\) and \\(z_2=1.65\\))  \n\n\nFind the area between \\(z_{1}=0.52\\) and \\(z_{2}=1.65\\).\nSolution:\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z_2=1.65\\) and to the right of \\(z_1 = 0.52\\)\nIf we look up the areas in the standard normal z-table we find:\n\\[\\begin{equation}\n\\text{left tail area for } z_2 =0.9505\n\\end{equation}\\]\n\\[\\begin{equation}\n\\text{left tail area for } z_1 =0.6985\n\\end{equation}\\]\nSo the area between is:\n\\[\\begin{equation}\n\\text{area between} =0.9505 - 0.6985 = 0.252\n\\end{equation}\\]\nRounded to the nearest percent this is 25%.\nThis means that the shaded area corresponds to 25% of the entire data.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nAnother one\n\nExample 16.5 (Find area between \\(z_1=-1.53\\) and \\(z_2=1.23\\))  \n\n\nFind the area between \\(z_{1}=-1.53\\) and \\(z_{2}=1.23\\).\nSolution:\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z_2=1.23\\) and to the right of \\(z_1 = -1.53\\)\nIf we look up the areas in the standard normal z-table we find:\n\\[\\begin{equation}\n\\text{left tail area for } z_2 =0.8907\n\\end{equation}\\]\n\\[\\begin{equation}\n\\text{left tail area for } z_1 =0.063\n\\end{equation}\\]\nSo the area between is:\n\\[\\begin{equation}\n\\text{area between} =0.8907 - 0.063 = 0.8277\n\\end{equation}\\]\nRounded to the nearest percent this is 83%.\nThis means that the shaded area corresponds to 83% of the entire data.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-areas.html#applications-of-standard-normal-distributions",
    "href": "standard-normal-areas.html#applications-of-standard-normal-distributions",
    "title": "16  Standard Normal Areas",
    "section": "16.4 Applications of Standard Normal Distributions",
    "text": "16.4 Applications of Standard Normal Distributions\nWe will see later in the text that service level in retail corresponds to the chance that a retailer would experience a lost sale (out of stock situation) for some period of interest.\n\nA service level of 90% means that lost sales would happen 10% of the time.\nA service level of 95% means that lost sales would happen be 5% of the time.\nA service level of 99% means that lost sales would happen be 1% of the time.\n\nFor demand that is distributed normally, the service level can be represented as a left tail area.\nIn addtion, the \\(z\\)-value that goes with a particular service level is called the service factor.\n\n\n\nservice level\nleft tail area\n\n\nservice factor\n\\(z\\)-value for that left tail area\n\n\n\n\nIf you know the service factor (\\(z\\)-value) you can find the service level (the left tail area). (this section)\nIf you know the service level (left tail area), you can find the service factor (\\(z\\)-value) (later in book)\n\n\nExample 16.6 (Service Level)  \n\n\nSuppose that monthly demand in units for a retail product is given by a normal distribution. Find the service level for service factor of \\(z=1.28\\).\nSolution:\nThe service level can be found by finding the left tail area for the given service factor \\(z\\)-value.\nWe have \\(z = 1.28\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z=1.28\\)\nIf we look up the area in the standard normal z-table using \\(z=1.28\\) we go to the row that has 1.2 and then to the column that contains .08 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n\n\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n\n\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.8997\n\\end{equation}\\]\nRounded to the nearest percent this is 90%. This means that the shaded area corresponds to 90% of the entire data.\nThis left tail area is the service level. A service level of \\(90\\%\\) means that there is just a \\(10\\%\\) chance of lost sales in given month.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-spreadsheet.html#left-tail-areas-with-spreadsheets",
    "href": "standard-normal-spreadsheet.html#left-tail-areas-with-spreadsheets",
    "title": "17  Standard Normal Areas And Spreadsheets",
    "section": "17.1 Left Tail Areas With Spreadsheets",
    "text": "17.1 Left Tail Areas With Spreadsheets\nSo here are a two examples of finding left tail area using a spreadsheet:\n\nExample 17.1 (Left tail area for \\(z=-1.02\\) using spreadsheet)  \n\n\nFind the left tail area when \\(z=-1.02\\) using a spreadsheet calculation.\nSolution:\nWe have \\(z = -1.02\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z=-1.02\\). We will calculate this area using a spreadsheet and the NORMSDIST function which gives left tail areas for z-values.\n\nType z in cell B2\nThen type \\(-1.02\\) into C2\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.02\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\nThen type in left tail area in B3,\nIn cell C3 type =NORMSDIST( then click on C2 then type ) then hit enter\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.02\n\n\n\n3\n\nleft tail area\n=NORMSDIST(C2)\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nAfter hitting enter you should see the result as follows:\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.02\n\n\n\n3\n\nleft tail area\n0.1539\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nRounded to the nearest percent this is 15%.\nThis means that the left tail area for \\(z=-1.02\\) is 15%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\n:::{#exm-Left-tail-area-for-z-equals-1.79-using-spreadsheet} ## Left tail area for \\(z=1.79\\) using spreadsheet\n\n\nFind the left tail area when \\(z=1.79\\) using a spreadsheet calculation.\nSolution:\nWe have \\(z = 1.79\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z=1.79\\). We will calculate this area using a spreadsheet and the NORMSDIST function which gives left tail areas for z-values.\n\nType z in cell B2\nThen type \\(1.79\\) into C2\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n1.79\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\nThen type in left tail area in B3,\nIn cell C3 type =NORMSDIST( then click on C2 then type ) then hit enter\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n1.79\n\n\n\n3\n\nleft tail area\n=NORMSDIST(C2)\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nAfter hitting enter you should see the result as follows:\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n1.79\n\n\n\n3\n\nleft tail area\n0.9633\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nRounded to the nearest percent this is 96%.\nThis means that the left tail area for \\(z=1.79\\) is 96%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-spreadsheet.html#right-tail-areas-with-spreadsheets",
    "href": "standard-normal-spreadsheet.html#right-tail-areas-with-spreadsheets",
    "title": "17  Standard Normal Areas And Spreadsheets",
    "section": "17.2 Right Tail Areas With Spreadsheets",
    "text": "17.2 Right Tail Areas With Spreadsheets\nAnd here are two examples of finding the right tail area using a spreadsheet:\n\nExample 17.2 (Right tail area for \\(z=-1.48\\) using spreadsheet)  \n\n\nFind the right tail area when \\(z=-1.48\\) using a spreadsheet calculation.\nSolution:\nWe have \\(z = -1.48\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the right of \\(z=-1.48\\).\nWe will calculate this area using a spreadsheet and the NORMSDIST function but because NORMSDIST finds left tails we have to use a trick. We actually will find the left tail area for this z-value, then subtract from 1.0 to get our right tail area.\n\nType z in cell B2\nThen type \\(-1.48\\) into C2\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.48\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\nThen type in right tail area in B3,\nIn cell C3 type =1.0-NORMSDIST( then click on C2 and then type ) then hit enter\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.48\n\n\n\n3\n\nright tail area\n=1.0-NORMSDIST(C2)\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nAfter hitting enter you should see the result as follows:\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n-1.48\n\n\n\n3\n\nright tail area\n0.9306\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nRounded to the nearest percent this is 93%.\nThis means that the right tail area for \\(z=-1.48\\) is 93%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\n\nExample 17.3 (Right tail area for \\(z=0.31\\) using spreadsheet)  \n\n\nFind the right tail area when \\(z=0.31\\) using a spreadsheet calculation.\nSolution:\nWe have \\(z = 0.31\\).\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the right of \\(z=0.31\\).\nWe will calculate this area using a spreadsheet and the NORMSDIST function but because NORMSDIST finds left tails we have to use a trick. We actually will find the left tail area for this z-value, then subtract from 1.0 to get our right tail area.\n\nType z in cell B2\nThen type \\(0.31\\) into C2\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n0.31\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\nThen type in right tail area in B3,\nIn cell C3 type =1.0-NORMSDIST( then click on C2 and then type ) then hit enter\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n0.31\n\n\n\n3\n\nright tail area\n=1.0-NORMSDIST(C2)\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nAfter hitting enter you should see the result as follows:\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz\n0.31\n\n\n\n3\n\nright tail area\n0.3783\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nRounded to the nearest percent this is 38%.\nThis means that the right tail area for \\(z=0.31\\) is 38%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "standard-normal-spreadsheet.html#area-between-with-spreadsheets",
    "href": "standard-normal-spreadsheet.html#area-between-with-spreadsheets",
    "title": "17  Standard Normal Areas And Spreadsheets",
    "section": "17.3 Area Between With Spreadsheets",
    "text": "17.3 Area Between With Spreadsheets\nAnd here is an example of finding the area between using a spreadsheet:\n\nExample 17.4 (Area between \\(z1=-0.54\\) and \\(z2=1.24\\) using spreadsheet)  \n\n\nFind the area between \\(z_{1}=-0.54\\) and \\(z_{2}=1.24\\) using a spreadsheet calculation.\nSolution:\nHere is the picture of the area we want.\n\n\n\n\n\n\n\n\n\nWe want the shaded region to the left of \\(z_2=1.24\\) and to the right of \\(z_1 = -0.54\\)\nWe will calculate this area using a spreadsheet and the NORMSDIST function.\nSince NORMSDIST gives us left tails we look up the left tail area for the greater z-value \\(z_2\\) and subtract the left tail area for the lesser z-value \\(z_1\\).\n\nType z1 in cell B2\nThen type \\(-0.54\\) into C2\nType z2 in cell B3\nThen type \\(1.24\\) into C3\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz1\n-0.54\n\n\n\n3\n\nz2\n1.24\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\n\nThen type in area between in B4,\nIn cell C4 enter =NORMSDIST(C3)-NORMSDIST(C2), and then hit enter\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz1\n-0.54\n\n\n\n3\n\nz2\n1.24\n\n\n\n4\n\narea between\n=NORMSDIST(C3)-NORMSDIST(C2)\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\nAfter hitting enter you should see the result as follows:\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n1\n\n\n\n\n\n\n2\n\nz1\n-0.54\n\n\n\n3\n\nz2\n1.24\n\n\n\n4\n\narea between\n0.5979\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\nRounded to the nearest percent this is 60%.\nThis means that the shaded area corresponds to 60% of the entire data.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "backwards-problems.html#solve-backwards-for-x-value",
    "href": "backwards-problems.html#solve-backwards-for-x-value",
    "title": "18  Backwards Problems",
    "section": "18.1 Solve Backwards for X-value",
    "text": "18.1 Solve Backwards for X-value\nOnce you have the z-value that you need using one of the above you can solve backward for the x-value that you need. It works like this:\nFind X-value by Solving Z-score Formula Backwards\n\nFind the z-value you need using technique above\nPlug the z-value into the z-score formula\nPlug in \\(\\mu\\) and \\(\\sigma\\) (these are known)\nSolve for the x-value\n\nSo basically you just plug your z-value, \\(\\mu\\) and \\(\\sigma\\) into this and solve for x:\n\\[\nz =\\frac{x-\\mu}{\\sigma}\n\\tag{18.1}\\]\nHere is an example where we want to find the lower 25% of the data. That means we want to find the x-value that has a left tail area of 25%.\n\nExample 18.3 (Find \\(x\\) for bottom \\(25\\%\\) of data)  \n\n\nSuppose that a normal distribution has mean \\(18\\) and standard deviation \\(3\\). Find the x-value that represents a left tail area of \\(25\\%\\).\nSolution:\nWe have \\(\\mu=18\\) and \\(\\sigma = 3\\).\nWe want an x-value whose left tail area is \\(0.25\\) (or \\(25\\%\\)).\nHere is what the picture looks like:\n\n\n\n\n\n\n\n\n\nTo do this we first find the z-value that goes with this same left tail area. It looks like this:\n\n\n\n\n\n\n\n\n\nWe use the table backwards and look for the closest z-value to our area 0.25. We may not find it exactly so we look for the entry that is closest to 0.25.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n\n\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n\n\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n\n\n\n\n\n\n\nWe get this z-value:\n\\[\\begin{equation}\nz = -0.67\n\\end{equation}\\]\nThen we can find the x-value by plugging in the z-value and the \\(\\mu=18\\) and \\(\\sigma = 3\\) (which were given) and solving for x:\n\\[\\begin{align}\nz &= \\frac{x-\\mu}{\\sigma} \\\\\n-0.67 &= \\frac{x-18}{3} \\\\\n3(-0.67) &= x-18 \\\\\n-2.01+ 18 &= x \\\\\n15.99 &= x\n\\end{align}\\]\nSteps to solve for x:\n\nPlug in \\(\\mu=18\\), \\(\\sigma=3\\) and \\(z=-0.67\\)\nMultiple by \\(3\\) on both sides\nAdd \\(18\\) to both sides as well\n\nThis gives us the x-value that we need. Here is the graph:\n\n\n\n\n\n\n\n\n\nSo \\(x=15.99\\) is the x-value that has a left tail area of \\(25\\)%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nHere is an example where we want to find the upper 15% of the data. That means we want to find the x-value that has a right tail area of 15%.\n\nExample 18.4 (Find \\(x\\) for top \\(15\\%\\) of data)  \n\n\nSuppose that a normal distribution has mean \\(23\\) and standard deviation \\(4\\). Find the x-value that represents a right tail area of \\(15\\%\\).\nSolution:\nWe have \\(\\mu=23\\) and \\(\\sigma = 4\\).\nWe want an x-value whose right tail area is \\(0.15\\) (or \\(15\\%\\)).\nHere is what the picture looks like:\n\n\n\n\n\n\n\n\n\nTo do this we first find the z-value that goes with this same right tail area.\n\n\n\n\n\n\n\n\n\nSince the right tail is 0.15, the left tail is 0.85 and so we just need to find the z-value that corresponds to a left tail area of 0.85.\nWe use the table backwards and look for the closest z-value to our area 0.85. We may not find it exactly so we look for the entry that is closest to 0.85.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n\n\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n\n\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n\n\n\n\n\n\n\nWe get this z-value:\n\\[\nz = 1.04\n\\]\nThen we can find the x-value by plugging in the z-value and the \\(\\mu=23\\) and \\(\\sigma = 4\\) (which were given) and solving for x:\n\\[\\begin{align}\nz &= \\frac{x-\\mu}{\\sigma} \\\\\n1.04 &= \\frac{x-23}{4} \\\\\n4(1.04) &= x-23 \\\\\n4.16+ 23 &= x \\\\\n27.16 &= x\n\\end{align}\\]\nSteps to solve for x:\n\nPlug in \\(\\mu=23\\), \\(\\sigma=4\\) and \\(z=1.04\\)\nMultiple by \\(4\\) on both sides\nAdd \\(23\\) to both sides as well.\n\nThis gives us the x-value that we need. Here is the graph:\n\n\n\n\n\n\n\n\n\nSo \\(x=27.16\\) is the x-value that has a right tail area of \\(15\\)%.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "backwards-problems.html#applications-of-backwards-problems",
    "href": "backwards-problems.html#applications-of-backwards-problems",
    "title": "18  Backwards Problems",
    "section": "18.2 Applications of Backwards Problems",
    "text": "18.2 Applications of Backwards Problems\nHere is an example where you want to find out when a demand value would be in the bottom 10% of your demand expectations for an item.\n\nExample 18.5 (Bottom \\(10\\%\\) of Demand Values)  \n\n\nSuppose you have a retail item SKU with demand on average of 257 units per month with a standard deviation of 45. What demand would correspond to the bottom 10% of all demand values here?\nSolution:\nWe have \\(\\mu=257\\) and \\(\\sigma = 45\\).\nWe want an x-value whose left tail area is \\(0.1\\) (or \\(10\\%\\)).\nHere is what the picture looks like:\n\n\n\n\n\n\n\n\n\nTo do this we first find the z-value that goes with this same left tail area. It looks like this:\n\n\n\n\n\n\n\n\n\nWe use the table backwards and look for the closest z-value to our area 0.1. We may not find it exactly so we look for the entry that is closest to 0.1.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n\n\n\n\n\n\n\nWe get this z-value:\n\\[\\begin{equation}\nz = -1.28\n\\end{equation}\\]\nThen we can find the x-value by plugging in the z-value and the \\(\\mu=257\\) and \\(\\sigma = 45\\) (which were given) and solving for x:\n\\[\\begin{align}\nz &= \\frac{x-\\mu}{\\sigma} \\\\\n-1.28 &= \\frac{x-257}{45} \\\\\n45(-1.28) &= x-257 \\\\\n-57.6+ 257 &= x \\\\\n199.4 &= x\n\\end{align}\\]\nSteps to solve for x:\n\nPlug in \\(\\mu=257\\), \\(\\sigma=45\\) and \\(z=-1.28\\)\nMultiple by \\(45\\) on both sides\nAdd \\(257\\) to both sides as well\n\nThis gives us the x-value that we need. Here is the graph:\n\n\n\n\n\n\n\n\n\nSo \\(x=199.4\\) is the x-value that has a left tail area of \\(10\\)%.\nSo any demand value below this would be in the bottom \\(10\\%\\) of the demand expectations for this SKU.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nHere is another application of backwards problems:\nThe service level in retail corresponds to the chance that a retailer would experience a lost sale (out of stock situation) for some period of interest.\n\nA service level of 90% means that lost sales would happen 10% of the time.\nA service level of 95% means that lost sales would happen be 5% of the time.\nA service level of 99% means that lost sales would happen be 1% of the time.\n\nDifferent items and categories can have different service levels as well, with some items being “high” service level items while others being “low” service level items.\nThe next example shows how to set inventory levels for an item to achieve a certain service level.\n\nExample 18.6 (Inventory For \\(95\\%\\) service level)  \n\n\nSuppose you have a retail item SKU with demand on average of \\(340\\) units per month with a standard deviation of \\(80\\). What level inventory should you carry in the upcoming month to assure that you have \\(95\\%\\) service level on this item?\nSolution:\nWe have \\(\\mu=340\\) and \\(\\sigma = 80\\).\nWe want an x-value whose left tail area is \\(0.95\\) (or \\(95\\%\\)).\nHere is what the picture looks like:\n\n\n\n\n\n\n\n\n\nTo do this we first find the z-value that goes with this same left tail area. It looks like this:\n\n\n\n\n\n\n\n\n\nWe use the table backwards and look for the closest z-value to our area 0.95. We may not find it exactly so we look for the entry that is closest to 0.95.\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n\n\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n\n\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n\n\n\n\n\n\n\nWe get this z-value:\n\\[\\begin{equation}\nz = 1.64\n\\end{equation}\\]\nThen we can find the x-value by plugging in the z-value and the \\(\\mu=340\\) and \\(\\sigma = 80\\) (which were given) and solving for x:\n\\[\\begin{align}\nz &= \\frac{x-\\mu}{\\sigma} \\\\\n1.64 &= \\frac{x-340}{80} \\\\\n80(1.64) &= x-340 \\\\\n131.2+ 340 &= x \\\\\n471.2 &= x\n\\end{align}\\]\nSteps to solve for x:\n\nPlug in \\(\\mu=340\\), \\(\\sigma=80\\) and \\(z=1.64\\)\nMultiple by \\(80\\) on both sides\nAdd \\(340\\) to both sides as well\n\nThis gives us the x-value that we need. Here is the graph:\n\n\n\n\n\n\n\n\n\nSo \\(x=471.2\\) is the x-value that has a left tail area of \\(95\\)%.\nSo you should have at least \\(472\\) for inventory to insure you have a \\(95\\%\\) service level.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nIn this interpretation service level corresponds to a certain left tail area for the normal distribution:\n\nA service level of 90% means you want a left tail area of 90%\nA service level of 95% means you want a left tail area of 95%.\nA service level of 99% means you want a left tail area of 99%.\n\nOr you can say it this way as well:\n\nA service level of 90% means you have lost sales 10% of the time.\nA service level of 95% means you have lost sales 5% of the time.\nA service level of 99% means you have lost sales 1% of the time."
  },
  {
    "objectID": "sample-proportions-distribution.html#repeated-sampling-for-proportions",
    "href": "sample-proportions-distribution.html#repeated-sampling-for-proportions",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.1 Repeated Sampling For Proportions",
    "text": "19.1 Repeated Sampling For Proportions\nSuppose we start with a population that has a certain population proportion \\(p\\).\nThen imagine we take samples of a certain size \\(n\\) over and over again, each time we calculate the sample proportion \\(\\hat p\\).\nSo we:\n\nchoose a sample and calculate a sample proportion \\(\\hat p\\)\nchoose a sample and calculate another sample proportion \\(\\hat p\\)\nchoose a sample and calculate another sample proportion \\(\\hat p\\)\nand so on\n\nUsually the sample proportions are close to the population proportion \\(p\\) but sometimes they are farther away (though this is less likely the farther away we get from the population proportion).\nIt turns out…\nIf we then plot all these sample proportions on a histogram, we get something that looks like a normal curve!"
  },
  {
    "objectID": "sample-proportions-distribution.html#coke-vs-pepsi-example",
    "href": "sample-proportions-distribution.html#coke-vs-pepsi-example",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.2 Coke vs Pepsi Example",
    "text": "19.2 Coke vs Pepsi Example\nLets show this with a made up example.\nSuppose the population proportion of students that prefer coke to pepsi is \\(p=0.65\\).\nThis means for the whole student population:\n\n65% prefer coke\n35% prefer pepsi\n\n(We don’t allow choosing neither as an answer here…its binary)\nSuppose we take samples of size \\(n=100\\) students with the following results:\n\nThe first sample has \\(\\hat p = 0.67\\) prefer coke\nThe second sample has \\(\\hat p = 0.66\\) prefer coke\nThe third sample has \\(\\hat p = 0.57\\) prefer coke\nand so on\n\nHere are the sample proportions that we get for the first 50 samples:\n\n\n\n\n\n0.67\n0.66\n0.57\n0.69\n0.67\n0.60\n0.71\n0.78\n0.62\n0.65\n\n\n0.66\n0.76\n0.63\n0.64\n0.57\n0.65\n0.66\n0.75\n0.61\n0.61\n\n\n0.62\n0.66\n0.67\n0.66\n0.63\n0.68\n0.68\n0.61\n0.62\n0.70\n\n\n0.71\n0.66\n0.64\n0.64\n0.63\n0.70\n0.62\n0.73\n0.56\n0.66\n\n\n0.66\n0.62\n0.68\n0.72\n0.64\n0.64\n0.64\n0.63\n0.70\n0.64\n\n\n\n\n\nSuppose we continue and do this 300 times…\nFinally let’s plot all of these sample proportions together in a histogram:\n\n\n\n\n\nWe can see that the shape of the distribution is normal"
  },
  {
    "objectID": "sample-proportions-distribution.html#sampling-distribution-of-sample-proportions",
    "href": "sample-proportions-distribution.html#sampling-distribution-of-sample-proportions",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.3 Sampling Distribution of Sample Proportions",
    "text": "19.3 Sampling Distribution of Sample Proportions\nThis distribution of the sample proportions is called the sampling distribution of sample proportions or the \\(\\hat p\\)-distribution.\nSampling distributions are made by repeatedly taking samples then computing a statistic, then collecting that data and graphing it in a histogram."
  },
  {
    "objectID": "sample-proportions-distribution.html#central-limit-theorem---proportions",
    "href": "sample-proportions-distribution.html#central-limit-theorem---proportions",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.4 Central Limit Theorem - Proportions",
    "text": "19.4 Central Limit Theorem - Proportions\nIt turns out that this “normal curve” shape turns up all the time for sampling distributions under the right conditions, and that fact is called the Central Limit Theorem.\nThis is one of the most important results in statistics and basically it tells us that we can use a normal distribution to approximate the sampling distribution (the \\(\\hat p\\)-distribution that is).\nThis will allow us to calculate areas for the \\(\\widehat{p}\\) distribution by calculating z-values and using a standard normal curve to find areas we want.\n\nTheorem 19.1 (Central Limit Theorem-Proportions)  \n\nWhen we use a large population with a population proportion of \\(p\\) and consider samples of size n from this population\n\nThe \\(\\hat p\\) distribution is approximately normal, becoming more and more accurate as n is larger\n\nThe mean and standard deviation of the \\(\\hat p\\) distribution are given by these formulas:\n\n\\[\n\\text{mean} = p\n\\]\n\\[\n\\text{standard deviation} = \\sqrt{\\frac{p(1-p)}{n}}\n\\]\n\nFor the above to be valid must have \\(n(p)&gt;5\\) and \\(n(1-p)&gt;5\\).\n\n\n\nThe first bullet point of this theorem says:\n\nwe can use a standard normal table to calculate areas under the \\(\\widehat{p}\\)-distribution\n\nThe second bullet point says:\n\nthe \\(\\widehat{p}\\)-distribution has \\(p\\) as the center of it, and the standard deviation we can compute with the formula in the theorem.\n\nThe third bullet point says:\n\nYou have to compute \\(n(p)\\) and \\(n(1-p)\\) and make sure they are at least \\(5\\). Otherwise you cannot use this approach."
  },
  {
    "objectID": "sample-proportions-distribution.html#how-to-calculate-hat-p-distribution-areas",
    "href": "sample-proportions-distribution.html#how-to-calculate-hat-p-distribution-areas",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.5 How to Calculate \\(\\hat p\\)-distribution Areas",
    "text": "19.5 How to Calculate \\(\\hat p\\)-distribution Areas\nSo to find areas under the \\(\\widehat{p}\\) distribution we will just convert them to areas under a standard normal curve like we did before but this time we will use this formula for the z-scores:\n\\[\nz=\\frac{\\hat p-p}{\\sqrt{\\frac{(1-p)(p)}{n}}}\n\\]\nSo just like before we will find left tails, right tails and areas between but this time using the z-value formula above."
  },
  {
    "objectID": "sample-proportions-distribution.html#examples-of-areas-for-hat-p-distribution",
    "href": "sample-proportions-distribution.html#examples-of-areas-for-hat-p-distribution",
    "title": "19  Sampling Distribution of Sample Proportions",
    "section": "19.6 Examples of Areas For \\(\\hat p\\)-distribution",
    "text": "19.6 Examples of Areas For \\(\\hat p\\)-distribution\nLets see some examples of computing areas for the \\(\\hat p\\)-distribution.\nFirst lets see how to compute a left tail area:\n\nExample 19.1 (Left Tail Area for \\(\\hat p\\)-distribution)  \n\n\nSuppose we have a population proportion of \\(79\\%\\) and take a sample of size \\(250\\). Suppose the sample proportion from that sample is \\(190\\) out of \\(250\\). What is the chance of getting that sample proportion or less?\nSolution:\nWe have population proportion of \\(p=0.79\\) and sample proportion of \\(190\\) out of \\(250\\).\nWe are interested in how likely it is we get our sample proportion or below.\nFirst let’s calculate our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{190}{250} = 0.76\n\\end{equation}\\]\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(250)(0.79)= 197.5\\) and \\(n(1-p)=(250)(0.21)= 52.5\\)\nSince these are both at least \\(5\\) we are in good shape.\nHere is the \\(\\hat p\\)-distribution showing the area that we want:\n\n\n\n\n\n\n\n\n\nNotice:\n\nThe sample proportion \\(\\hat p=0.76\\) is at the edge of the shaded region we want to find.\nThe population proportion \\(p =0.79\\) is in the center.\n\nWe want the shaded left tail area that is to the left of \\(\\hat p = 0.76\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.79)0.79}{250}}\n=\\sqrt{\\frac{(0.21)0.79}{250}}\n=\\sqrt{\\frac{0.1659}{250}}\n=0.0257604\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.76\\) the population proportion \\(p=0.79\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.76-0.79}{0.0257604}\n=\\frac{-0.03}{0.0257604}\n=-1.16\n\\end{equation}\\]\nSo here is the equivalent left tail area for of \\(z=-1.16\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can look up the area in the standard normal z-table using \\(z=-1.16\\)\nWe go to the row that has -1.1 and then to the column that contains .06 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n\n\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.123\n\\end{equation}\\]\nRounded to the nearest percent this is 12%. This means that the shaded area corresponds to 12% of the entire data.\nThis means there is a 12% chance of getting a sample proportion of \\(\\hat p=0.76\\) or less for this population when using samples of size \\(n = 250\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nNow lets see how to compute a right tail area:\n\nExample 19.2 (Right Tail Area for \\(\\hat p\\)-distribution)  \n\n\nSuppose we have a population proportion of \\(61\\%\\) and take a sample of size \\(320\\). Suppose the sample proportion from that sample is \\(208\\) out of \\(320\\). What is the chance of getting that sample proportion or more?\nSolution:\nWe have population proportion of \\(p=0.61\\) and sample proportion of \\(208\\) out of \\(320\\).\nWe are interested in how likely it is we get our sample proportion or above.\nFirst let’s calculate our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{208}{320} = 0.65\n\\end{equation}\\]\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(320)(0.61)= 195.2\\) and \\(n(1-p)=(320)(0.39)= 124.8\\)\nSince these are both at least \\(5\\) we are in good shape.\nHere is the \\(\\hat p\\)-distribution showing the area that we want:\n\n\n\n\n\n\n\n\n\nNotice:\n\nThe sample proportion \\(\\hat p=0.65\\) is at the edge of the shaded region we want to find.\nThe population proportion \\(p =0.61\\) is in the center.\n\nWe want the shaded right tail area that is to the right of \\(\\hat p = 0.65\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.61)0.61}{320}}\n=\\sqrt{\\frac{(0.39)0.61}{320}}\n=\\sqrt{\\frac{0.2379}{320}}\n=0.0272661\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.65\\) the population proportion \\(p=0.61\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.65-0.61}{0.0272661}\n=\\frac{0.04}{0.0272661}\n=1.47\n\\end{equation}\\]\nSo here is the equivalent right tail area for of \\(z=1.47\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can find the right tail area for \\(z=1.47\\) by finding the left tail area and then subtracting that from 1.0.\nSo lets look up the left tail area first. Go to the row that has 1.4 and then to the column that contains .07 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n\n\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n\n\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.9292\n\\end{equation}\\]\nThis means that the right tail that we want to find is going to be this left tail subtracted from 1.0.\n\\[\\begin{equation}\n\\text{right tail area} = 1.0 - 0.9292 = 0.0708\n\\end{equation}\\]\nRounded to the nearest percent this is 7%. This means the shaded right tail area corresponds to 7% of the entire data.\nThis means there is a 7% chance of getting a sample proportion of \\(\\hat p=0.65\\) or more for this population when using samples of size \\(n = 320\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "confidence-intervals-prop.html#steps-for-finding-confidence-intervals---proportions",
    "href": "confidence-intervals-prop.html#steps-for-finding-confidence-intervals---proportions",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.1 Steps for Finding Confidence Intervals - Proportions",
    "text": "20.1 Steps for Finding Confidence Intervals - Proportions\nThe steps involved to do this are as follows:\n\nTake a sample and calculate the sample proportion \\(\\hat p\\)\nCalculate a margin of error \\(E\\) using the formula below. (This tells us roughly how far off \\(\\hat p\\) is from \\(p\\))\nFind the interval by adding and subtracting \\(E\\) to \\(\\hat p\\). (This interval tells where we hope to find \\(p\\))\n\n\nExample 20.1 (A Confidence Interval and Margin of Error)  \n\nSuppose we take a sample and collect some data. Then we compute a sample proportion:\n\\[\n\\hat p = .41\n\\]\nThen using the formula for a confidence interval suppose we find that\n\\[\nE = .03\n\\]\n(We will show how to compute this later on. For now just pretend we did it and got \\(.03\\).)\nSubtract \\(E\\) from \\(\\hat p\\) to get the lower endpoint of the confidence interval:\n\\[\n\\hat p - E = .41 - .03 = .38\n\\]\nAdd \\(E\\) to \\(\\hat p\\) to get the upper endpoint of the confidence interval:\n\\[\n\\hat p + E = .41 + .03 = .44\n\\]\nSo the confidence interval goes from .38 up to .44. Sometimes we write this like this:\n\\[\n(\\hat{p} - E,\\ \\hat{p} + E) = (.38,.44)\n\\]\nRoughly what this says is that we believe the population proportion is between 38% and 44%.\nExactly how confident and in what sense the above is true we will see below.\n\n\\[ \\tag*{$\\blacksquare$} \\]\n\nNext we look at how we come up with \\(E\\), the margin of error."
  },
  {
    "objectID": "confidence-intervals-prop.html#margin-of-error-e-for-confidence-intervals---proportions",
    "href": "confidence-intervals-prop.html#margin-of-error-e-for-confidence-intervals---proportions",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.2 Margin of Error E for Confidence Intervals - Proportions",
    "text": "20.2 Margin of Error E for Confidence Intervals - Proportions\nTo find \\(E\\) we have to first decide on a confidence level. This is a percentage (something like 90% or 95% or 99%).\nThe confidence level describes how confident we are that our confidence intervals will contain the population proportion:\n\nA confidence level of 95% means that our confidence intervals (\\(\\widehat{p} - E\\), \\(\\widehat{p} + E\\)) will contain the population proportion \\(p\\) about 95% of the time.\nA confidence level of 99% means that our confidence intervals (\\(\\widehat{p} - E\\), \\(\\widehat{p} + E\\)) will contain the population proportion \\(p\\) about 99% of the time.\nand so on\n\nAnother way to put this:\nFor 95% confidence, this means that if we repeatedly take samples and find a sample proportion \\(\\hat p\\), we can expect to find the population proportion inside our confidence intervals roughly 95% of the time.\nThis notion of confidence level makes sense only in the context of repeatedly taking confidence intervals for a particular situation.\nOf the different confidence levels, by far the most commonly used confidence interval is one with confidence level 95%.\nOnce we decide on the confidence level we want to use, we will use the following formula to calculate the margin of error \\(E\\):\n\\[\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n\\]\nThe \\(\\hat p\\) we have and the sample size \\(n\\) we have as well. The \\(z^\\star\\) comes from the chosen confidence level. We show where to get it in the next section."
  },
  {
    "objectID": "confidence-intervals-prop.html#critical-value-zstar",
    "href": "confidence-intervals-prop.html#critical-value-zstar",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.3 Critical Value \\(z^\\star\\)",
    "text": "20.3 Critical Value \\(z^\\star\\)\nThe formula for E has something called \\(z^\\star\\) in it. This is called the critical value. It comes directly from the confidence level. Once you know the confidence interval you are using you can look up the \\(z^\\star\\) that goes with that confidence level. Here are the most typical values:\n\n\n\nConfidence Level\n80%\n90%\n95%\n99%\n99.9%\n\n\n\n\n\\(z^\\star\\)\n1.282\n1.645\n1.960\n2.576\n3.291\n\n\n\nAs an example, this table says:\n\nuse 1.645 for the \\(z^\\star\\) if you are computing a 90% confidence interval\nuse 1.960 for the \\(z^\\star\\) if you are computing a 95% confidence interval\n\nIf you ever need a confidence interval for some confidence level not shown in the table above you can compute it yourself using a spreadsheet as follows:\n= NORMSINV( (c+1.0)/2)\nwhere c = confidence level as a proportion. For example if the confidence level was 97% (which is not on the table above) then you could get it in a spreadsheet with\n=NORMSINV((.97+1.0)/2)\nAs part of using the normal distribution to find the \\(z^\\star\\) we also have to check the technical conditions like in the Central Limit Theorem.\nFor the above to be valid must have \\(n(\\hat p)&gt;5\\) and \\(n(1-\\hat p)&gt;5\\)."
  },
  {
    "objectID": "confidence-intervals-prop.html#confidence-interval-calculations---proportions",
    "href": "confidence-intervals-prop.html#confidence-interval-calculations---proportions",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.4 Confidence Interval Calculations - Proportions",
    "text": "20.4 Confidence Interval Calculations - Proportions\n\nExample 20.2 (A \\(95\\%\\) Confidence Interval)  \n\n\nSuppose we have a sample proportion of \\(210\\) out of \\(250\\). Find a \\(95\\%\\) confidence interval for this sample proportion.\nSolution:\nThe sample proportion is \\(210\\) out of \\(250\\):\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{210}{250} = 0.84\n\\end{equation}\\]\nBefore we start we check the conditions showing we can use z-values from a standard normal distribution here: \\(n(\\hat p)=(250)(0.84)= 210\\) and \\(n(1-\\hat p)=(250)(0.16)= 40\\)\nSince these are both at least \\(5\\) we are in good shape.\nNext we will calculate the \\(E\\) involved, using the confidence level 95%.\nFor this confidence level we can look up that the appropriate critical value \\(z^\\star\\) to use. In this case it is \\(z^\\star = 1.96\\).\nWe plug the sample proportion \\(\\hat p=0.84\\) and the sample size \\(n=250\\) and the \\(z^\\star\\) into our formula for \\(E\\):\n\\[\\begin{equation}\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n=(1.96)\\sqrt{\\frac{(1-0.84)(0.84)}{250}}\n= 0.045\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\hat p - E = 0.84-0.045 = 0.795\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\hat p + E = 0.84+0.045 = 0.885\n\\end{equation}\\]\nSo the confidence interval for the sample proportion is\n\\[\\begin{equation}\n(0.795,0.885)\n\\end{equation}\\]\nIf we wanted this rounded to the nearest percent we would use:\n\\[\\begin{equation}\n(80 \\% ,88 \\%)\n\\end{equation}\\]\nWe could say the confidence interval is from \\(80 \\%\\) to \\(88 \\%\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "confidence-intervals-prop.html#effect-of-changing-confidence-level",
    "href": "confidence-intervals-prop.html#effect-of-changing-confidence-level",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.5 Effect of Changing Confidence Level",
    "text": "20.5 Effect of Changing Confidence Level\nWhat is the effect of changing the confidence level?\nThe higher the confidence level, the more sure we are of “capturing” the actual population proportion. But at the same time, the more sure we are of “capturing” the actual population proportion the wider our confidence intervals become.\n\nA 95% confidence interval will be wider than a 90% confidence interval.\nA 99% confidence interval will be wider than a 95% confidence interval.\nand so on\n\nIt is kind of like if we cast a larger net we will be sure to catch it in the net somewhere, but then we are less sure exactly where it is because the net is bigger.\nLet’s see an example where we calculate the confidence interval twice, each time using a different confidence level.\n\nFirst we compute it for 90% confidence level\nSecond we compute it for 99% confidence level\n\n\nExample 20.3 (First Version - 90% Confidence Level)  \n\nSuppose we have a sample proportion of \\(50\\) out of \\(125\\). Find a \\(90\\%\\) confidence interval for this sample proportion.\nSolution:\nThe sample proportion is \\(50\\) out of \\(125\\):\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{50}{125} = 0.4\n\\end{equation}\\]\nBefore we start we check the conditions showing we can use z-values from a standard normal distribution here: \\(n(\\hat p)=(125)(0.4)= 50\\) and \\(n(1-\\hat p)=(125)(0.6)= 75\\)\nSince these are both at least \\(5\\) we are in good shape.\nNext we will calculate the \\(E\\) involved, using the confidence level 90%.\nFor this confidence level we can look up that the appropriate critical value \\(z^\\star\\) to use. In this case it is \\(z^\\star = 1.645\\).\nWe plug the sample proportion \\(\\hat p=0.4\\) and the sample size \\(n=125\\) and the \\(z^\\star\\) into our formula for \\(E\\):\n\\[\\begin{equation}\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n=(1.645)\\sqrt{\\frac{(1-0.4)(0.4)}{125}}\n= 0.072\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\hat p - E = 0.4-0.072 = 0.328\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\hat p + E = 0.4+0.072 = 0.472\n\\end{equation}\\]\nSo the confidence interval for the sample proportion is\n\\[\\begin{equation}\n(0.328,0.472)\n\\end{equation}\\]\nIf we wanted this rounded to the nearest percent we would use:\n\\[\\begin{equation}\n(33 \\% ,47 \\%)\n\\end{equation}\\]\nWe could say the confidence interval is from \\(33 \\%\\) to \\(47 \\%\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\nNow let’s do that last one over with a 99% confidence level.\n\nExample 20.4 (Second Version - \\(99\\%\\) Confidence Level)  \n\n\nSuppose we have a sample proportion of \\(50\\) out of \\(125\\). Find a \\(99\\%\\) confidence interval for this sample proportion.\nSolution:\nThe sample proportion is \\(50\\) out of \\(125\\):\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{50}{125} = 0.4\n\\end{equation}\\]\nBefore we start we check the conditions showing we can use z-values from a standard normal distribution here: \\(n(\\hat p)=(125)(0.4)= 50\\) and \\(n(1-\\hat p)=(125)(0.6)= 75\\)\nSince these are both at least \\(5\\) we are in good shape.\nNext we will calculate the \\(E\\) involved, using the confidence level 99%.\nFor this confidence level we can look up that the appropriate critical value \\(z^\\star\\) to use. In this case it is \\(z^\\star = 2.576\\).\nWe plug the sample proportion \\(\\hat p=0.4\\) and the sample size \\(n=125\\) and the \\(z^\\star\\) into our formula for \\(E\\):\n\\[\\begin{equation}\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n=(2.576)\\sqrt{\\frac{(1-0.4)(0.4)}{125}}\n= 0.113\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\hat p - E = 0.4-0.113 = 0.287\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\hat p + E = 0.4+0.113 = 0.513\n\\end{equation}\\]\nSo the confidence interval for the sample proportion is\n\\[\\begin{equation}\n(0.287,0.513)\n\\end{equation}\\]\nIf we wanted this rounded to the nearest percent we would use:\n\\[\\begin{equation}\n(29 \\% ,51 \\%)\n\\end{equation}\\]\nWe could say the confidence interval is from \\(29 \\%\\) to \\(51 \\%\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nWhich confidence interval was wider in the above?\nThe 99% confidence level one.\nTo be more confident that your confidence interval contains the population proportion it must be wider.\nOf course this means your estimate is less accurate and that is reflected in the range of the interval being larger."
  },
  {
    "objectID": "confidence-intervals-prop.html#applications-of-confidence-intervals",
    "href": "confidence-intervals-prop.html#applications-of-confidence-intervals",
    "title": "20  Confidence Intervals For Proportions",
    "section": "20.6 Applications of Confidence Intervals",
    "text": "20.6 Applications of Confidence Intervals\n\nExample 20.5 (Shopping App Usage)  \n\n\nA department store thinks that \\(40\\%\\) of their customers would use a shopping app while in-store. They poll \\(300\\) users one day and find out that \\(78\\) of them would use such an app. Find a \\(90\\%\\) confidence interval for this sample proportion.\nSolution:\nThe sample proportion is \\(78\\) out of \\(300\\):\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{78}{300} = 0.26\n\\end{equation}\\]\nBefore we start we check the conditions showing we can use z-values from a standard normal distribution here: \\(n(\\hat p)=(300)(0.26)= 78\\) and \\(n(1-\\hat p)=(300)(0.74)= 222\\)\nSince these are both at least \\(5\\) we are in good shape.\nNext we will calculate the \\(E\\) involved, using the confidence level 90%.\nFor this confidence level we can look up that the appropriate critical value \\(z^\\star\\) to use. In this case it is \\(z^\\star = 1.645\\).\nWe plug the sample proportion \\(\\hat p=0.26\\) and the sample size \\(n=300\\) and the \\(z^\\star\\) into our formula for \\(E\\):\n\\[\\begin{equation}\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n=(1.645)\\sqrt{\\frac{(1-0.26)(0.26)}{300}}\n= 0.042\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\hat p - E = 0.26-0.042 = 0.218\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\hat p + E = 0.26+0.042 = 0.302\n\\end{equation}\\]\nSo the confidence interval for the sample proportion is\n\\[\\begin{equation}\n(0.218,0.302)\n\\end{equation}\\]\nIf we wanted this rounded to the nearest percent we would use:\n\\[\\begin{equation}\n(22 \\% ,30 \\%)\n\\end{equation}\\]\nWe could say the confidence interval is from \\(22 \\%\\) to \\(30 \\%\\).\nThe confidence interval does not contain \\(40\\%\\) and so probably the store is overestimating what proportion of their customers would use such an app. It appears to be somewhat less than \\(40\\%\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nIn the next example we estimate the chance of being out of stock for some item we are selling.\n\nExample 20.6 (Estimating Out Of Stock)  \n\n\nA store had some item out of stock in \\(26\\) of the past \\(208\\) weeks (the last 4 years). Calculate a \\(90\\%\\) confidence interval estimate for the proportion of weeks this item is out of stock.\nSolution:\nThe sample proportion is \\(26\\) out of \\(208\\):\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{26}{208} = 0.125\n\\end{equation}\\]\nBefore we start we check the conditions showing we can use z-values from a standard normal distribution here: \\(n(\\hat p)=(208)(0.125)= 26\\) and \\(n(1-\\hat p)=(208)(0.875)= 182\\)\nSince these are both at least \\(5\\) we are in good shape.\nNext we will calculate the \\(E\\) involved, using the confidence level 90%.\nFor this confidence level we can look up that the appropriate critical value \\(z^\\star\\) to use. In this case it is \\(z^\\star = 1.645\\).\nWe plug the sample proportion \\(\\hat p=0.125\\) and the sample size \\(n=208\\) and the \\(z^\\star\\) into our formula for \\(E\\):\n\\[\\begin{equation}\nE=(z^\\star)\\sqrt{\\frac{(1-\\hat p)(\\hat p)}{n}}\n=(1.645)\\sqrt{\\frac{(1-0.125)(0.125)}{208}}\n= 0.038\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\hat p - E = 0.125-0.038 = 0.087\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\hat p + E = 0.125+0.038 = 0.163\n\\end{equation}\\]\nSo the confidence interval for the sample proportion is\n\\[\\begin{equation}\n(0.087,0.163)\n\\end{equation}\\]\nIf we wanted this rounded to the nearest percent we would use:\n\\[\\begin{equation}\n(9 \\% ,16 \\%)\n\\end{equation}\\]\nWe could say the confidence interval is from \\(9 \\%\\) to \\(16 \\%\\).\nOur estimate is between \\(9 \\%\\) and \\(16 \\%\\)\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "hypothesis-testing-proportions.html#steps-for-hypothesis-testing",
    "href": "hypothesis-testing-proportions.html#steps-for-hypothesis-testing",
    "title": "21  Hypothesis Testing - Proportions",
    "section": "21.1 Steps for Hypothesis Testing",
    "text": "21.1 Steps for Hypothesis Testing\nNote: We use \\(p_{0}\\) as the notation for the proposed population proportion. You should think of this as an actual number like \\(.32\\) or \\(.75\\). It is the claimed population proportion.\n\n1) Write down the claimed null hypothesis\n\\(H_{0}:\\ p = p_{0}\\)\nThis is called null hypothesis (or “H zero”) and its interpretation in words is this:\n“The population proportion is equal to \\(p_{0}\\)”\n\n\n2) Write down the alternative hypothesis\nThis will be one of the following types:\n\n\\(H_{a}:\\ p &lt; p_{0}\\) (This one is called a left tail test )\n\nThis one is interpreted “the population proportion is less than \\(p_{0}\\)”\n\n\\(H_{a}:\\ p &gt; p_{0}\\) (This one is called a right tail test )\n\nThis one is interpreted “the population proportion is greater than \\(p_{0}\\)”\n\n\\(H_{a}:\\ p \\neq p_{0}\\) (This one is called a two tail test )\n\nThis one is interpreted “the population proportion is not equal to \\(p_{0}\\)”\nWhich of these you pick depends on what you (as the researcher) want to show about the population proportion:\n\nIf you think it is actually smaller than what was claimed, pick the left tail test\nIf you think it is actually bigger than what was claimed, pick the right tail test\nIf you just want to show its different from what was claimed, and you don’t care about how it is different (bigger or smaller would be fine from your viewpoint), pick the two tailed test\n\n\n\n3) Take a (random) sample from the population and compute the sample proportion\n\\[\n\\widehat{p} = \\frac{count}{\\text{sample size}} = \\frac{count}{n}\n\\]\nThis is called the test statistic\n\n\n4) Compute the z-score for the test statistic\n\\[\nz = \\frac{\\widehat{p}-p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}}\n\\]\nHere you use the (proposed) population proportion \\(p_{0}\\) and the \\(\\widehat{p}\\) is the sample proportion you got in the previous step.\n\n\n5) Find the the P-value\nThe P-value is what you use to conclude your test.\nIts value represents the chance that you get your sample proportion or something more extreme given that the null hypothesis is true.\nIn more concrete terms, it is going to be an area (left tail, right tail or both) that comes from your sample proportion.\nHere is how you compute it:\n\nFor left tail test, the \\(P = \\text{left tail area}\\)\nFor right tail test, the \\(P = \\text{right tail area}\\)\nFor two tail test, the \\(P = 2(\\text{area of tail})\\)\n\nTo get these areas you just use the z-value from step #4 above and compute them from that.\n\n\n6a) Find the conclusion from the P-value\nTo find your conclusion for a hypothesis test once you have your P-value you can use the following guide based on the size of the P-value:\n\nP-value bigger than .1, then little or no evidence against  \\({H_{0}}_{}\\)\nP-value between .05 and .1, then some evidence against \\({H_{0}}_{}\\)\nP-value between .01 and .05, then moderate evidence against \\({H_{0}}_{}\\)\nP-value between .001 and .01, then strong evidence against \\({H_{0}}_{}\\)\nP-value less than .001, then very strong evidence against \\({H_{0}}_{}\\)\n\nOne thing to notice about the conclusions is: small P-values are evidence against the null hypothesis.\nThat’s because a small P-value represents a small area for a tail and that happens when the z-value (and hence the sample proportion) is more extreme.\n\nExample 21.1 (Conclusion of Hypothesis Test)  \n\nSuppose you are doing a hypothesis test and you find out that your P-value is \\(p=.047\\).\nSince\n\\[\n.01 &lt; .047 &lt; .05\n\\]\nThis means that your conclusion is moderate evidence against the null \\(H_0\\).\n\n\n\n\n6b) Find the conclusion from level of significance\nSometimes the conclusion part of a hypothesis test is done in a different way than the above step 6a.\nIf you are given a level of significance (called \\(\\alpha\\)) you decide your conclusion in a slightly different way:\n\nIf \\(P &lt; \\alpha\\), then you Reject the null hypothesis\nIf \\(P \\geq \\alpha\\), then you Fail to reject the null hypothesis\n\nSome people use the term accept the null hypothesis instead of fail to reject the null hypothesis. We take these to be equivalent.\nUsing the level of signifcance like this means you state your conclusion differently than in section 6a above. The \\(\\alpha\\) is more like a cut-off for rejecting the null hypothesis in this case.\nAnd in the case you either reject the null or fail to reject the null, and there is no othersituation (no “moderate evidence” or “very strong evidence”… just reject or not plain and simple)\n\nExample 21.2 (Level of Significance)  \n\nSuppose you are doing a hypothesis test at the 5% level of significance,(which is \\(\\alpha=.05\\)) and you find out that your P-value is \\(P=.023\\).\nSince\n\\[\n.023 &lt; .05\n\\]\nThis means that \\(P &lt; \\alpha\\) and so you reject the null hypothesis.\n\n\nSo in this case you decide your conclusion by comparing to the given \\(\\alpha\\) value and not by the method in section 6a. If your P-value is smaller than \\(\\alpha\\), you reject the null hypothesis, otherwise you fail to reject the null hypothesis."
  },
  {
    "objectID": "hypothesis-testing-proportions.html#other-terminology",
    "href": "hypothesis-testing-proportions.html#other-terminology",
    "title": "21  Hypothesis Testing - Proportions",
    "section": "21.2 Other terminology",
    "text": "21.2 Other terminology\nSometimes you will hear people say accept the null hypothesis when \\(p \\geq \\alpha\\). This is just a different way of saying fail to reject the null hypothesis.\nFinally keep this is mind as well:\n\nreject the null hypothesis means you believe the alternative\nfailure to reject the null hypothesis means you believe the null could be true\n\nAnd one more that is like a court case verdict:\n\nreject the null hypothesis is in favor of \\(H_a\\)\nfailure to reject the null hypothesis is in favor of \\(H_0\\)"
  },
  {
    "objectID": "hypothesis-testing-proportions.html#type-i-and-type-ii-error",
    "href": "hypothesis-testing-proportions.html#type-i-and-type-ii-error",
    "title": "21  Hypothesis Testing - Proportions",
    "section": "21.3 Type I and Type II Error",
    "text": "21.3 Type I and Type II Error\nLet us take a minute to mention two types of errors that take place with hypothesis testing called Type I Error and Type II Error.\nHere are the complete options when you’re dealing with these hypothesis tests. Recall that \\(H_0\\) stands for the null hypothesis. Also we will use the phrase \"accept \\(H_0\\)\" instead of \"fail to reject \\(H_0\\)\". These mean the same thing.\n\nIf \\(H_0\\) is actually true and in our testing we accept \\(H_0\\) then there is no mistake\nIf \\(H_0\\) is actually false and in our testing we reject \\(H_0\\) then there is no mistake\nIf \\(H_0\\) is actually true and in our testing we reject \\(H_0\\) then that is a mistake and this is called a Type I Error\nIf \\(H_0\\) is actually false and in our testing we accept \\(H_0\\) then that is a mistake and this is called a Type II Error.\n\nMost people give a guilty vs. innocent example so we will too.\n\nIf an innocent person is not convicted then there is no mistake\nIf a guilty person is convicted then there is no mistake\nIf an innocent person is convicted then that is a mistake and is called a Type I Error\nIf a guilty person is not convicted then that is a mistake and is called a Type II Error\n\nThese errors can impact our daily lives in a huge way, like in the example mentioned above. More everyday examples include construction projects, our safety, and more."
  },
  {
    "objectID": "hypothesis-testing-proportions.html#examples-of-hypothesis-testing",
    "href": "hypothesis-testing-proportions.html#examples-of-hypothesis-testing",
    "title": "21  Hypothesis Testing - Proportions",
    "section": "21.4 Examples of Hypothesis Testing",
    "text": "21.4 Examples of Hypothesis Testing\nThe first example is a left tail test:\n\nExample 21.3 (Left Tail Hypothesis Test Proportions)  \n\n\nSuppose someone claims a population proportion is \\(79\\%\\) but we believe that it is less than this. To test this we take a sample proportion and get \\(190\\) out of \\(250\\). Perform a hypothesis test for this situation.\nSolution:\nThe claim about the population proportion involves \\(0.79\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:p &= 0.79 \\\\\nH_a:p &&lt; 0.79\n\\end{align}\\]\n\nThe null hypothesis says The population proportion is \\(0.79\\)\nThe alternative hypothesis says The population proportion is less than \\(0.79\\)\n\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(250)(0.79)= 197.5\\) and \\(n(1-p)=(250)(0.21)= 52.5\\)\nSince these are both at least \\(5\\) we are in good shape.\nNow if the null hypothesis is true, the Central Limit Theorem says the sampling distribution of sample proportions would look like this:\n\n\n\n\n\n\n\n\n\nNext we look at our test statistic, which is just our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{190}{250} = 0.76\n\\end{equation}\\]\nSo we want to know how likely it is to get a sample proportion of 0.76 in this situation.\nIn fact the P-value is just this left tail area\n\n\n\n\n\n\n\n\n\nWe want the shaded left tail area that is to the left of \\(\\hat p = 0.76\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.79)0.79}{250}}\n=\\sqrt{\\frac{(0.21)0.79}{250}}\n=\\sqrt{\\frac{0.1659}{250}}\n=0.0257604\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.76\\), the population proportion \\(p=0.79\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.76-0.79}{0.0257604}\n=\\frac{-0.03}{0.0257604}\n=-1.16\n\\end{equation}\\]\nSo here is the equivalent left tail area for of \\(z=-1.16\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can look up the area in the standard normal z-table using \\(z=-1.16\\)\nWe go to the row that has -1.1 and then to the column that contains .06 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n\n\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n\n\n\n\n\n\n\nSo that means the P-value we need in this situation is:\n\\[\\begin{equation}\nP = \\text{left tail area} =0.123\n\\end{equation}\\]\nSo based on this our conclusion is that this is little or no evidence against the null hypothesis.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nNow let’s see an example of a right tail test:\n\nExample 21.4 (Right Tail Hypothesis Test-Proportions)  \n\n\nSuppose someone claims a population proportion is \\(34\\%\\) but we believe that it is more than this. To test this we take a sample proportion and get \\(101\\) out of \\(250\\). Perform a hypothesis test for this situation.\nSolution:\nThe claim about the population proportion involves \\(0.34\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:p &= 0.34 \\\\\nH_a:p &&gt; 0.34\n\\end{align}\\]\n\nThe null hypothesis says The population proportion is \\(0.34\\)\nThe alternative hypothesis says The population proportion is more than \\(0.34\\)\n\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(250)(0.34)= 85\\) and \\(n(1-p)=(250)(0.66)= 165\\)\nSince these are both at least \\(5\\) we are in good shape.\nNow if the null hypothesis is true, the Central Limit Theorem says the sampling distribution of sample proportions would look like this:\n\n\n\n\n\n\n\n\n\nNext we look at our test statistic, which is just our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{101}{250} = 0.404\n\\end{equation}\\]\nSo we want to know how likely it is to get a sample proportion of 0.404 in this situation.\nIn fact the P-value is just this right tail area\n\n\n\n\n\n\n\n\n\nWe want the shaded right tail area that is to the right of \\(\\hat p = 0.404\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.34)0.34}{250}}\n=\\sqrt{\\frac{(0.66)0.34}{250}}\n=\\sqrt{\\frac{0.2244}{250}}\n=0.02996\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.404\\) the population proportion \\(p=0.34\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.404-0.34}{0.02996}\n=\\frac{0.064}{0.02996}\n=2.14\n\\end{equation}\\]\nSo here is the equivalent right tail area for of \\(z=2.14\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can find the right tail area for \\(z=2.14\\) by finding the left tail area and then subtracting that from 1.0.\nSo lets look up the left tail area first. Go to the row that has 2.1 and then to the column that contains .04 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n\n\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n\n\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n\n\n\n\n\n\n\nSo that means the left tail area we need in this situation is:\n\\[\\begin{equation}\n\\text{left tail area} =0.9838\n\\end{equation}\\]\nThis means that the right tail that we want to find is going to be this left tail subtracted from 1.0.\n\\[\\begin{equation}\nP = \\text{right tail area} = 1.0 - 0.9838 = 0.0162\n\\end{equation}\\]\nSo based on this our conclusion is that this is moderate evidence against the null hypothesis.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "hypothesis-testing-proportions.html#applications-of-hypothesis-testing",
    "href": "hypothesis-testing-proportions.html#applications-of-hypothesis-testing",
    "title": "21  Hypothesis Testing - Proportions",
    "section": "21.5 Applications of Hypothesis Testing",
    "text": "21.5 Applications of Hypothesis Testing\nHere is an application about selling clothes online:\n\nExample 21.5 (Selling Clothes Online)  \n\n\nYour company is trying to figure out what percentage of students sell clothes online at a website like Poshmark at some point in their college career. They think that \\(40\\%\\) of students do it. You believe it is more than this. You take a sample of \\(700\\) graduating seniors. You find out that \\(313\\) of them have sold clothes online at some point while in college. Does your evidence support the claim of your company?\nSolution:\nThe claim about the population proportion involves \\(0.4\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:p &= 0.4 \\\\\nH_a:p &&gt; 0.4\n\\end{align}\\]\n\nThe null hypothesis says The population proportion is \\(0.4\\)\nThe alternative hypothesis says The population proportion is more than \\(0.4\\)\n\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(700)(0.4)= 280\\) and \\(n(1-p)=(700)(0.6)= 420\\)\nSince these are both at least \\(5\\) we are in good shape.\nNow if the null hypothesis is true, the Central Limit Theorem says the sampling distribution of sample proportions would look like this:\n\n\n\n\n\n\n\n\n\nNext we look at our test statistic, which is just our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{313}{700} = 0.4471429\n\\end{equation}\\]\nSo we want to know how likely it is to get a sample proportion of 0.4471429 in this situation.\nIn fact the P-value is just this right tail area\n\n\n\n\n\n\n\n\n\nWe want the shaded right tail area that is to the right of \\(\\hat p = 0.4471429\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.4)0.4}{700}}\n=\\sqrt{\\frac{(0.6)0.4}{700}}\n=\\sqrt{\\frac{0.24}{700}}\n=0.0185164\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.4471429\\) the population proportion \\(p=0.4\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.4471429-0.4}{0.0185164}\n=\\frac{0.0471429}{0.0185164}\n=2.55\n\\end{equation}\\]\nSo here is the equivalent right tail area for of \\(z=2.55\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can find the right tail area for \\(z=2.55\\) by finding the left tail area and then subtracting that from 1.0.\nSo lets look up the left tail area first. Go to the row that has 2.5 and then to the column that contains .05 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n\n\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n\n\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n\n\n\n\n\n\n\nSo that means the left tail area we need in this situation is:\n\\[\\begin{equation}\n\\text{left tail area} =0.9946\n\\end{equation}\\]\nThis means that the right tail that we want to find is going to be this left tail subtracted from 1.0.\n\\[\\begin{equation}\nP = \\text{right tail area} = 1.0 - 0.9946 = 0.0054\n\\end{equation}\\]\nSo based on this our conclusion is that this is strong evidence against the null hypothesis.\nThis evidence supports your claim that it is more than \\(40\\%\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nHere is one about testing promotion effectiveness:\n\nExample 21.6 (Promotion Effectiveness)  \n\n\nSuppose a store manager thinks that \\(25\\%\\) of its customers would upgrade to a more expensive item during a promotion. You work there as well and find the store manager's claim too high. To find out, you sample \\(200\\) customers and find out \\(38\\) of them would upgrade. Does the evidence support the store manager's claim?\nSolution:\nThe claim about the population proportion involves \\(0.25\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:p &= 0.25 \\\\\nH_a:p &&lt; 0.25\n\\end{align}\\]\n\nThe null hypothesis says The population proportion is \\(0.25\\)\nThe alternative hypothesis says The population proportion is less than \\(0.25\\)\n\nBefore we start we check the conditions of the Central Limit Theorem to make sure we can use a normal distribution here:\n\\(np=(200)(0.25)= 50\\) and \\(n(1-p)=(200)(0.75)= 150\\)\nSince these are both at least \\(5\\) we are in good shape.\nNow if the null hypothesis is true, the Central Limit Theorem says the sampling distribution of sample proportions would look like this:\n\n\n\n\n\n\n\n\n\nNext we look at our test statistic, which is just our sample proportion:\n\\[\\begin{equation}\n\\hat p = \\frac{count}{n} = \\frac{38}{200} = 0.19\n\\end{equation}\\]\nSo we want to know how likely it is to get a sample proportion of 0.19 in this situation.\nIn fact the P-value is just this left tail area\n\n\n\n\n\n\n\n\n\nWe want the shaded left tail area that is to the left of \\(\\hat p = 0.19\\):\nWe will find this area by changing the sample proportion \\(\\hat p\\) into a z-value and using the standard normal table.\nFirst we need the calculation of the standard deviation since we need this in our z-value calculation:\n\\[\\begin{equation}\n\\small{\nstdev=\\sqrt{\\frac{(1-p)p}{n}}\n=\\sqrt{\\frac{(1-0.25)0.25}{200}}\n=\\sqrt{\\frac{(0.75)0.25}{200}}\n=\\sqrt{\\frac{0.1875}{200}}\n=0.0306186\n}\n\\end{equation}\\]\nNow lets find the z-value using the sample proportion \\(\\hat p= 0.19\\), the population proportion \\(p=0.25\\) and the standard deviation \\(stdev\\) we just found:\n\\[\\begin{equation}\nz=\\frac{\\hat p-p}{stdev}\n=\\frac{0.19-0.25}{0.0306186}\n=\\frac{-0.06}{0.0306186}\n=-1.96\n\\end{equation}\\]\nSo here is the equivalent left tail area for of \\(z=-1.96\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can look up the area in the standard normal z-table using \\(z=-1.96\\)\nWe go to the row that has -1.9 and then to the column that contains .06 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n\n\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n\n\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n\n\n\n\n\n\n\nSo that means the P-value we need in this situation is:\n\\[\\begin{equation}\nP = \\text{left tail area} =0.025\n\\end{equation}\\]\nSo based on this our conclusion is that this is moderate evidence against the null hypothesis.\nSo this does not support the claim of the store manager. It looks like you were correct.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "sample-means-distribution.html#repeated-sampling-for-means",
    "href": "sample-means-distribution.html#repeated-sampling-for-means",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.1 Repeated Sampling For Means",
    "text": "22.1 Repeated Sampling For Means\nSuppose we start with a population distribution that has a certain population mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nThere is nothing special about this distribution. For example, it does not have to be normal. It could be. But what we are going to do works for any distribution actually.\nWe will call this the original distribution, and sometimes we refer to it as the \\(x\\)-distribution.\nThen imagine we take samples of a certain size \\(n\\) over and over again, each time we calculate the sample mean \\(\\bar x\\) from our sample.\nSo we:\n\nchoose a sample and calculate a sample mean \\(\\bar x\\)\nchoose a sample and calculate another sample mean \\(\\bar x\\)\nchoose a sample and calculate another sample mean \\(\\bar x\\)\nand so on\n\nUsually the sample means are close to the population mean but sometimes they are farther away (though this is less likely the farther away we get from the population mean).\nIt turns out…\nIf we then plot all these sample means on a histogram, we get something that looks like a normal curve!\nThis is true if the sample size is big enough even if we start with the original distribution not being normal."
  },
  {
    "objectID": "sample-means-distribution.html#start-with-an-original-distribution-x-distribution",
    "href": "sample-means-distribution.html#start-with-an-original-distribution-x-distribution",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.2 Start With An Original Distribution (\\(x\\)-distribution)",
    "text": "22.2 Start With An Original Distribution (\\(x\\)-distribution)\nHere we start with an original distribution which is normal (call it the \\(x\\)-distribution). It has mean \\(\\mu=50\\) and standard deviation of \\(\\sigma = 12\\).\nLets pick some samples from this distribution and plot them so we can get and idea what this distribution looks like. Here is a plot of 400 data values from it:\n\n\n\n\n\nWe can see that roughly the standard deviation is about \\(\\sigma=12\\).\nYou can also see that most of the data is between \\(\\mu-3(\\sigma)\\) and \\(\\mu+3(\\sigma)\\), which is the same as \\(z=-3\\) up to \\(z=+3\\):\nLet's see what those values are:\n\n\\(\\mu-3\\sigma=50-3(12)=14\\)\n\\(\\mu+3\\sigma=50+3(12)=86\\)\n\nWe know this is true for every normal curve actually. Most of the data is within 3 standard deviations of the mean."
  },
  {
    "objectID": "sample-means-distribution.html#taking-sample-means",
    "href": "sample-means-distribution.html#taking-sample-means",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.3 Taking Sample Means",
    "text": "22.3 Taking Sample Means\nNow we will take samples from this distribution. For each sample we pick 10 data values from the original distribution and and then compute the sample mean \\(\\bar x\\) for that sample.\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nx̄\n\n\n\n\nSample 1\n69\n55\n55\n53\n59\n45\n66\n22\n63\n52\n53.9\n\n\nSample 2\n36\n52\n20\n44\n56\n47\n54\n60\n48\n55\n47.2\n\n\nSample 3\n54\n57\n46\n50\n61\n40\n48\n47\n35\n50\n48.8\n\n\nSample 4\n29\n61\n56\n53\n54\n31\n38\n55\n41\n56\n47.4\n\n\nSample 5\n50\n54\n47\n51\n63\n62\n35\n55\n64\n45\n52.6\n\n\n\n\n\nSuppose we continue and do this 400 times…\nLet's take a look at the sample means in a histogram:\n\n\n\n\n\nThis distribution is called the \\(\\bar x\\)-distribution. or the sampling distribution of sample means.\nIt is a very important distribution in statistics."
  },
  {
    "objectID": "sample-means-distribution.html#sampling-distribution-of-sample-means-bar-x-distribution",
    "href": "sample-means-distribution.html#sampling-distribution-of-sample-means-bar-x-distribution",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.4 Sampling Distribution of Sample Means (\\(\\bar x\\)-distribution)",
    "text": "22.4 Sampling Distribution of Sample Means (\\(\\bar x\\)-distribution)\nOne important thing we can see is that the shape of the \\(\\bar x\\)-distribution is normal.\nNext how does it compare to the original \\(x\\)-distribution?\nLet's see the graphs of the original \\(x\\)-distribution and the \\(\\bar x\\)-distribution side by side:\n\n\n\n\n\n\n\n\nWe can clearly see that the \\(\\bar x\\)-distribution is not as spread out as the original \\(x\\)-distribution. This is because when you take sample means, it averages the data out and when that happens it is more clustered towards the middle.\nIn fact this clustering towards the middle is one of the main ideas of the Central Limit Theorem below.\nAnd it turns out that we can tell how \"squished\" the \\(\\bar x\\)-distribution is…\nThe squish factor is just given by \\(\\sqrt{n}\\):\n\\[\n\\text{standard deviation of the }\\bar x\\text{-distribution} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nwhere \\(\\sigma\\) is the standard deviation of the original \\(x\\)-distribution.\nSo for example if we took an \\(\\bar x\\) using:\n\n\\(n=100\\) that would mean the \"squish\" factor is \\(\\sqrt{100}=10\\), the spread is reduced by factor of \\(10\\)\n\\(n=36\\) that would mean the \"squish\" factor is \\(\\sqrt{36}=6\\), the spread is reduced by factor of \\(6\\)\n\nSo for the example above that we used the squish factor is:\n\\[\n\\sqrt{n} = \\sqrt{10}=3.1622777\n\\]\nSo the standard deviation of the \\(\\bar x\\)-distribution is:\n\\[\n\\frac{\\sigma}{\\sqrt{n}} =\n   \\frac{12}{\\sqrt{10}} =\n   \\frac{12}{3.1622777}= 3.7947332\n\\]\nSo the \\(\\bar x\\)-distribution is more concentrated around the center \\(\\mu\\)\nAnd finally its important to note that sampling distributions are made by repeatedly taking samples then computing a statistic, then collecting that data and graphing it in a histogram."
  },
  {
    "objectID": "sample-means-distribution.html#central-limit-theorem---means",
    "href": "sample-means-distribution.html#central-limit-theorem---means",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.5 Central Limit Theorem - Means",
    "text": "22.5 Central Limit Theorem - Means\nIt turns out that this \"normal curve\" shape turns up all the time for sampling distributions under the right conditions, and that fact is called the Central Limit Theorem.\nThis is one of the most important results in statistics and basically it tells us that we can use a normal distribution to approximate the sampling distribution (the \\(\\bar x\\)-distribution that is).\nThis will allow us to calculate areas for the \\(\\bar x\\)-distribution by calculating z-values and using a standard normal curve to find areas we want.\n\nTheorem 22.1 (Central Limit Theorem - Means)  \n\nSuppose we have a large population with population mean \\(\\mu\\) and standard deviation \\(\\sigma\\) and consider samples of size \\(n\\) from this population.\nIf \\(n&gt;30\\) or if the population we start with is approximately normal:\n\nThe \\(\\bar x\\) distribution is normal\nThe mean and standard deviation of the \\(\\bar x\\) distribution are given by these formulas:\n\n\\[\n\\text{mean} = \\mu\n\\]\n\\[\n\\text{standard deviation} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nNote:\n\nif the population we start with is approximately normal the result is true for any sample size (even \\(n \\leq 30\\)).\nif the population we start with is not approximately normal, we must have \\(n&gt;30\\) for the result to be true.\n\nThe first bullet point of this theorem means:\n\nwe can use a standard normal table to calculate areas under the \\(\\bar x\\)-distribution\n\nThe second bullet point of the theorem means:\n\nthe \\(\\bar x\\)-distribution has \\(\\mu\\) as its center, and the standard deviation we can compute with the formula in the theorem."
  },
  {
    "objectID": "sample-means-distribution.html#how-to-calculate-bar-x-distribution-areas",
    "href": "sample-means-distribution.html#how-to-calculate-bar-x-distribution-areas",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.6 How to Calculate \\(\\bar x\\)-distribution Areas",
    "text": "22.6 How to Calculate \\(\\bar x\\)-distribution Areas\nSo to find areas under the \\(\\bar x\\)-distribution we will just convert them to areas under a standard normal curve like we did before but this time we will use this formula for the z-scores:\n\\[\nz=\\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n\\]\nSo just like before we will find left tails, right tails and areas between but this time using the z-value formula above."
  },
  {
    "objectID": "sample-means-distribution.html#examples-of-areas-for-bar-x-distribution",
    "href": "sample-means-distribution.html#examples-of-areas-for-bar-x-distribution",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.7 Examples of Areas For \\(\\bar x\\)-distribution",
    "text": "22.7 Examples of Areas For \\(\\bar x\\)-distribution\nLets see some examples of computing areas for the \\(\\bar x\\)-distribution.\nFirst lets see how to compute a left tail area:\n\nExample 22.1 (Left tail area for \\(\\bar x\\)-distribution when \\(\\bar x=210\\) \\(\\mu=220\\) \\(\\sigma=100\\), and \\(n=10\\))  \n\n\nSuppose that a normal distribution has a mean of \\(220\\) and a standard deviation of \\(100\\). If we take samples of size \\(10\\) from this distribution what is the chance that \\(\\bar x\\) will be \\(210\\) or less?\nSolution:\nWe have \\(\\bar x=210\\), \\(\\mu =220\\), \\(\\sigma=100\\) and \\(n=10\\).\nWe are interested in how likely it is to get a sample mean \\(\\bar x=210\\) or below for the \\(\\bar x\\)-distribution here.\nHere is the \\(\\bar x\\)-distribution showing the area that we want:\n\n\n\n\n\n\n\n\n\nNotice:\n\nThe sample mean \\(\\bar x=210\\) is at the edge of the shaded region we want to find\nThe population mean \\(\\mu =220\\) is in the center\n\nWe want the shaded left tail area that is to the left of \\(\\bar x = 210\\):\nWe will find this area by changing the sample mean \\(\\bar x\\) into a z-value and then using standard normal table.\nLets find the z-value using the form of the z-value formula for the \\(\\bar x\\)-distribution:\n\\[\\begin{equation}\nz=\\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n=\\frac{210-220}{\\frac{100}{\\sqrt{10}}}\n=\\frac{-10}{31.6227766}\n=-0.32\n\\end{equation}\\]\nNote that we use the \\(\\sqrt{n}\\) in the denominator. This is because we are using the \\(\\bar x\\)-distribution.\nSo here is the equivalent left tail area for of \\(z=-0.32\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can look up the area in the standard normal z-table using \\(z=-0.32\\)\nWe go to the row that has -0.3 and then to the column that contains .02 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n\n\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n\n\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.3745\n\\end{equation}\\]\nRounded to the nearest percent this is 37%. This means that the shaded area corresponds to 37% of the entire data.\nThis means there is a 37% chance of getting a sample proportion of \\(\\bar x=210\\) or less for the \\(\\bar x\\)-distribution with sample size of \\(n=10\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nNow lets see how to compute a right tail area:\n\nExample 22.2 (Right tail area for \\(\\bar x\\)-distribution when \\(\\bar x=80\\) \\(\\mu=90\\) \\(\\sigma=50\\), and \\(n=20\\))  \n\n\nSuppose that a normal distribution has a mean of \\(90\\) and a standard deviation of \\(50\\). If we take samples of size \\(20\\) from this distribution what is the chance that \\(\\bar x\\) will be \\(80\\) or more?\nSolution:\nWe have \\(\\bar x=80\\), \\(\\mu =90\\), \\(\\sigma=50\\) and \\(n=20\\).\nWe are interested in how likely it is to get a sample mean \\(\\bar x=80\\) or above for the \\(\\bar x\\)-distribution.\nHere is the \\(\\bar x\\)-distribution showing the area that we want:\n\n\n\n\n\n\n\n\n\nNotice:\n\nThe sample mean \\(\\bar x=80\\) is at the edge of the shaded region we want to find\nThe population mean \\(\\mu =90\\) is in the center\n\nWe want the shaded right tail area that is to the right of \\(\\bar x = 80\\):\nWe will find this area by changing the sample mean \\(\\bar x\\) into a z-value and then using standard normal table.\nLets find the z-value using the form of the z-value formula for the \\(\\bar x\\)-distribution:\n\\[\\begin{equation}\nz=\\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n=\\frac{80-90}{\\frac{50}{\\sqrt{20}}}\n=\\frac{-10}{11.1803399}\n=-0.89\n\\end{equation}\\]\nNote that we use the \\(\\sqrt{n}\\) in the denominator. This is because we are using the \\(\\bar x\\)-distribution.\nSo here is the equivalent left tail area for of \\(z=-0.89\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can find the right tail area for \\(z=-0.89\\) by finding the left tail area and then subtracting that from 1.0.\nSo lets look up the left tail area first. Go to the row that has -0.8 and then to the column that contains .09 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n\n\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n\n\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.1867\n\\end{equation}\\]\nThis means that the right tail that we want to find is going to be this left tail subtracted from 1.0.\n\\[\\begin{equation}\n\\text{right tail area} = 1.0 - 0.1867 = 0.8133\n\\end{equation}\\]\nRounded to the nearest percent this is 81%. This means the shaded right tail area corresponds to 81% of the entire data.\nThis means there is a 81% chance of getting a sample mean of \\(\\bar x=80\\) or more for this population when using samples of size \\(n = 20\\).\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "sample-means-distribution.html#applications-of-sampling-distribution-of-sample-means",
    "href": "sample-means-distribution.html#applications-of-sampling-distribution-of-sample-means",
    "title": "22  Sampling Distribution of Sample Means",
    "section": "22.8 Applications of Sampling Distribution of Sample Means",
    "text": "22.8 Applications of Sampling Distribution of Sample Means\n\nExample 22.3 (Average Monthly Demand)  \n\n\nSuppose that monthly demand in units for a retail product is given by a normal distribution that has a mean of \\(48\\) and standard deviation \\(14\\). Find the chance that that the average demand for the next 12 months is \\(40\\) or fewer units.\nSolution:\nWe have \\(\\bar x=40\\), \\(\\mu =48\\), \\(\\sigma=14\\) and \\(n=12\\).\nWe are interested in how likely it is to get a sample mean \\(\\bar x=40\\) or below for the \\(\\bar x\\)-distribution here.\nHere is the \\(\\bar x\\)-distribution showing the area that we want:\n\n\n\n\n\n\n\n\n\nNotice:\n\nThe sample mean \\(\\bar x=40\\) is at the edge of the shaded region we want to find\nThe population mean \\(\\mu =48\\) is in the center\n\nWe want the shaded left tail area that is to the left of \\(\\bar x = 40\\):\nWe will find this area by changing the sample mean \\(\\bar x\\) into a z-value and then using standard normal table.\nLets find the z-value using the form of the z-value formula for the \\(\\bar x\\)-distribution:\n\\[\\begin{equation}\nz=\\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n=\\frac{40-48}{\\frac{14}{\\sqrt{12}}}\n=\\frac{-8}{4.0414519}\n=-1.98\n\\end{equation}\\]\nNote that we use the \\(\\sqrt{n}\\) in the denominator. This is because we are using the \\(\\bar x\\)-distribution.\nSo here is the equivalent left tail area for of \\(z=-1.98\\).\n\n\n\n\n\n\n\n\n\nThis area is the same size as our original area so we just find this one using the standard normal distribution.\nWe can look up the area in the standard normal z-table using \\(z=-1.98\\)\nWe go to the row that has -1.9 and then to the column that contains .08 and we see this:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n\n\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n\n\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n\n\n\n\n\n\n\nSo that means:\n\\[\\begin{equation}\n\\text{left tail area} =0.0239\n\\end{equation}\\]\nRounded to the nearest percent this is 2%. This means that the shaded area corresponds to 2% of the entire data.\nThis means there is a 2% chance of getting a sample proportion of \\(\\bar x=40\\) or less for the \\(\\bar x\\)-distribution with sample size of \\(n=12\\). This is the chance the average demand for the next year is \\(40\\) or less.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "confidence-intervals-means.html#steps-for-finding-confidence-intervals---means",
    "href": "confidence-intervals-means.html#steps-for-finding-confidence-intervals---means",
    "title": "23  Confidence Intervals For Means",
    "section": "23.1 Steps for Finding Confidence Intervals - Means",
    "text": "23.1 Steps for Finding Confidence Intervals - Means\nThe steps involved to do this are as follows:\n\nTake a sample and calculate the sample mean \\(\\bar x\\)\nCalculate a margin of error \\(E\\) using the formula below. (This tells us roughly how far off \\(\\mu\\) is from \\(\\bar x\\))\nFind the interval by adding and subtracting \\(E\\) to \\(\\bar x\\). (This interval tells where we hope to find \\(\\mu\\))\n\n\nSuppose we take a sample and collect some data. Then we compute a sample mean:\n\\[\n\\bar x = 131\n\\]\nThen using the formula for a confidence interval suppose we find that\n\\[\nE = 22\n\\]\n(We will show how to compute this later on. For now just pretend we did it and got \\(22\\).)\nSubtract \\(E\\) from \\(\\bar x\\) to get the lower endpoint of the confidence interval:\n\\[\n\\bar x - E = 131 - 22 = 109\n\\]\nAdd \\(E\\) to \\(\\bar x\\) to get the upper endpoint of the confidence interval:\n\\[\n\\bar x + E = 131 + 22 = 153\n\\]\nSo the confidence interval goes from 109 up to 153. Sometimes we write this like this:\n\\[\n(\\bar x - E,\\ \\bar x + E) = (109,153)\n\\]\nRoughly what this says is that we believe the population mean is between 109 and 153.\nExactly how confident and in what sense the above is true we will see below.\n\nNext we look at how we come up with \\(E\\), the margin of error."
  },
  {
    "objectID": "confidence-intervals-means.html#margin-of-error-e-for-confidence-intervals---means",
    "href": "confidence-intervals-means.html#margin-of-error-e-for-confidence-intervals---means",
    "title": "23  Confidence Intervals For Means",
    "section": "23.2 Margin of Error E for Confidence Intervals - Means",
    "text": "23.2 Margin of Error E for Confidence Intervals - Means\nTo find \\(E\\) we have to first decide on a confidence level. This is a percentage (something like 90% or 95% or 99%).\nThe confidence level describes how confident we are that our confidence intervals will contain the population mean:\n\nA confidence level of 95% means that our confidence intervals (\\(\\bar x - E\\), \\(\\bar x + E\\)) will contain the population mean \\(\\mu\\) about 95% of the time.\nA confidence level of 99% means that our confidence intervals (\\(\\bar x - E\\), \\(\\bar x + E\\)) will contain the population mean \\(\\mu\\) about 95% of the time.\nand so on\n\nAnother way to put this:\nFor 95% confidence, this means that if we repeatedly take samples and find a sample mean \\(\\bar x\\), we can expect to find the population mean inside our confidence intervals roughly 95% of the time.\nThis notion of confidence level makes sense only in the context of repeatedly taking confidence intervals for a particular situation.\nOf the different confidence levels, by far the most commonly used confidence interval is one with confidence level 95%.\nOnce we decide on the confidence level we want to use, we will use the following formula to calculate the margin of error E:\n\\[\nE=(t^\\star)\\frac{s}{\\sqrt{n}}\n\\]\nThe \\(s\\) is the sample standard deviation, the \\(n\\) is the sample size and the \\(t^\\star\\) comes from the chosen confidence level. We show where to get it in the next section."
  },
  {
    "objectID": "confidence-intervals-means.html#critical-value-tstar",
    "href": "confidence-intervals-means.html#critical-value-tstar",
    "title": "23  Confidence Intervals For Means",
    "section": "23.3 Critical Value \\(t^\\star\\)",
    "text": "23.3 Critical Value \\(t^\\star\\)\nThe formula for E has something called \\(t^\\star\\) in it. This is called the critical value. It comes directly from the confidence level. Once you know the confidence level you are using you can use the following formula for \\(t^\\star\\) that goes with that confidence level \\(c\\). Here is what you should use in a spreadsheet:\n=TINV(1.0-c, n-1)\nwhere \\(c\\) is the confidence level as a decimal (so for example 95% would be .95) and \\(n\\) is the sample size."
  },
  {
    "objectID": "confidence-intervals-means.html#confidence-interval-calculations---means",
    "href": "confidence-intervals-means.html#confidence-interval-calculations---means",
    "title": "23  Confidence Intervals For Means",
    "section": "23.4 Confidence Interval Calculations - Means",
    "text": "23.4 Confidence Interval Calculations - Means\n\nExample 23.1 (A \\(99\\%\\) Confidence Interval for Means)  \n\n\nSuppose a sample mean is given by \\(12.4\\). Find a 99% confidence interval for this sample mean given the sample standard deviation \\(s = 5.1\\) and the sample size \\(n=38\\).\nSolution:\nFirst we will calculate the \\(t^\\star\\) involved, using the confidence level 99%.\nIn a spreadsheet we do the following:\n=TINV(1.0-confidence, n-1)\nSince \\(n=38\\), in this case this will look like this:\n=TINV(0.01, 37)\nIf we do this we get\n\\[\nt^\\star = 2.7154087\n\\]\nWe now plug into the formula for E using the sample standard deviation, the sample size and the \\(t^\\star\\):\n\\[\\begin{equation}\nE=(t^\\star)\\frac{s}{\\sqrt{n}}\n=(2.7154087)\\frac{5.1}{6.164414}\n= 2.2465371\n\\end{equation}\\]\nThen we find the two endpoints.\nThe left one is this:\n\\[\\begin{equation}\n\\bar x - E = 12.4-2.2465371 = 10.1534629\n\\end{equation}\\]\nThe right one is this:\n\\[\\begin{equation}\n\\bar x + E = 12.4+2.2465371 = 14.6465371\n\\end{equation}\\]\nSo the confidence interval for this sample mean is:\n\\[\\begin{equation}\n(10.15,14.65)\n\\end{equation}\\]\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "hypothesis-testing-means.html#steps-for-hypothesis-testing---means-sigma-unknown",
    "href": "hypothesis-testing-means.html#steps-for-hypothesis-testing---means-sigma-unknown",
    "title": "24  Hypothesis Testing - Means",
    "section": "24.1 Steps for Hypothesis Testing - Means (\\(\\sigma\\) unknown)",
    "text": "24.1 Steps for Hypothesis Testing - Means (\\(\\sigma\\) unknown)\nNote: We use \\(\\mu_{0}\\) as the notation for the proposed population mean. You should think of this as an actual number like \\(52\\) or \\(312\\). It is the claimed population mean.\n\n1) Write down the claimed null hypothesis\n\\(H_{0}:\\ \\mu = \\mu_{0}\\)\nThis is called null hypothesis (or “H zero”) and its interpretation in words is this:\n“The population mean is equal to \\(\\mu_{0}\\)”\n\n\n2) Write down the alternative hypothesis\nThis will be one of the following types:\n\n\\(H_{a}:\\ \\mu &lt; \\mu_{0}\\) (This one is called a left tail test )\n\nThis one is interpreted “the population mean is less than \\(\\mu_{0}\\)”\n\n\\(H_{a}:\\ \\mu &gt; \\mu_{0}\\) (This one is called a right tail test )\n\nThis one is interpreted “the population mean is greater than \\(\\mu_{0}\\)”\n\n\\(H_{a}:\\ \\mu \\neq \\mu_{0}\\) (This one is called a two tail test )\n\nThis one is interpreted “the population mean is not equal to \\(\\mu_{0}\\)”\nWhich of these you pick depends on what you (as the researcher) want to show about the population mean:\n\nIf you think it is actually smaller than what was claimed, pick the left tail test\nIf you think it is actually bigger than what was claimed, pick the right tail test\nIf you just want to show its different from what was claimed, and you don’t care about how it is different (bigger or smaller would be fine from your viewpoint), pick the two tailed test\n\n\n\n3) Take a (random) sample from the population and compute the sample mean and the sample standard deviation\nsample mean: \\[\n\\bar x = \\frac{\\sum x}{n}\n\\]\nsample standard deviation:\n\\[\ns = \\sqrt{\\frac{\\sum (x-\\bar x)^2}{n-1}}\n\\]\nThe \\(\\bar x\\) is called the test statistic\n\n\n4) Compute the t-score for the test statistic\n\\[\nt = \\frac{\\bar x-\\mu_{0}}{\\frac{s}{\\sqrt{n}}}\n\\]\nHere you use the (proposed) population mean \\(\\mu_{0}\\) and the sample mean \\(\\bar x\\) and the sample standard deviation \\(s\\) from the test statistic\n\n\n5) Find the the P-value\nThe P-value is what you use to conclude your test.\nIts value represents the chance that you get your sample mean or something more extreme given that the null hypothesis is true.\nIn more concrete terms, it is going to be an area (left tail, right tail or both) that comes from your t-value and the t-distribution.\nHere is how you compute it:\n\nFor left tail test, the \\(P = \\text{left tail area}\\)\nFor right tail test, the \\(P = \\text{right tail area}\\)\nFor two tail test, the \\(P = 2(\\text{area of tail})\\)\n\nTo get these areas you just use the t-value from step #4 above and compute them from that using tables or software.\n\n\n6a) Find the conclusion from the P-value\nTo find your conclusion for a hypothesis test once you have your P-value you can use the following guide based on the size of the P-value:\n\nP-value bigger than .1, then little or no evidence against  \\({H_{0}}_{}\\)\nP-value between .05 and .1, then some evidence against \\({H_{0}}_{}\\)\nP-value between .01 and .05, then moderate evidence against \\({H_{0}}_{}\\)\nP-value between .001 and .01, then strong evidence against \\({H_{0}}_{}\\)\nP-value less than .001, then very strong evidence against \\({H_{0}}_{}\\)\n\nOne thing to notice about the conclusions is: small P-values are evidence against the null hypothesis.\nThat’s because a small P-value represents a small area for a tail and that happens when the t-value (and hence the sample mean) is more extreme.\n\n\n6b) Find the conclusion from level of significance\nSometimes the conclusion part of a hypothesis test is done in a different way than the above step 6a.\nIf you are given a level of significance (called \\(\\alpha\\)) you decide your conclusion in a slightly different way:\n\nIf \\(P &lt; \\alpha\\), then you Reject the null hypothesis\nIf \\(P \\geq \\alpha\\), then you Fail to reject the null hypothesis\n\nSome people use the term accept the null hypothesis instead of fail to reject the null hypothesis. We take these to be equivalent.\nUsing the level of signifcance like this means you state your conclusion differently than in section 6a above. The \\(\\alpha\\) is more like a cut-off for rejecting the null hypothesis in this case.\nAnd in the case you either reject the null or fail to reject the null, and there is no other situation (no “moderate evidence” or “very strong evidence”… just reject or not plain and simple)\nSo in this case you decide your conclusion by comparing to the given \\(\\alpha\\) value and not by the method in section 6a. If your P-value is smaller than \\(\\alpha\\), you reject the null hypothesis, otherwise you fail to reject the null hypothesis."
  },
  {
    "objectID": "hypothesis-testing-means.html#steps-for-hypothesis-testing---means-sigma-known",
    "href": "hypothesis-testing-means.html#steps-for-hypothesis-testing---means-sigma-known",
    "title": "24  Hypothesis Testing - Means",
    "section": "24.2 Steps for Hypothesis Testing - Means (\\(\\sigma\\) known)",
    "text": "24.2 Steps for Hypothesis Testing - Means (\\(\\sigma\\) known)\nIn this situation the test is exactly like above except that instead of using a t-value after you get your \\(\\bar x\\) test statistic, you can use a z-value and the standard normal distribution to perform your calculations. So in step 4 above you compute this:\n\\[\nz = \\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n\\]\nIt should be noted that in the case where \\(n&lt;30\\) you must make assumptions as in the Central Limit Theorem that the distribution approximately normal."
  },
  {
    "objectID": "hypothesis-testing-means.html#examples-of-hypothesis-testing---means",
    "href": "hypothesis-testing-means.html#examples-of-hypothesis-testing---means",
    "title": "24  Hypothesis Testing - Means",
    "section": "24.3 Examples of Hypothesis Testing - Means",
    "text": "24.3 Examples of Hypothesis Testing - Means\nThe first example is a left tail test where \\(\\sigma\\) is known, so we use a z-test (use a z-value) in our calculations:\n\nExample 24.1 (Left Tail Hypothesis Test \\(\\sigma\\) known)  \n\n\nSuppose that we wish to test if a population mean is less than \\(50\\). We take a sample of size \\(n=40\\) and get \\(\\bar x=48\\). Suppose that the population standard deviation is \\(\\sigma=5\\)\nSolution:\nWe have \\(\\bar x = 48\\), \\(\\sigma = 5\\) and \\(n=40\\).\nThe claim about the population mean involves \\(50\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:\\mu &= 50 \\\\\nH_a:\\mu &&lt; 50\n\\end{align}\\]\n\nThe null hypothesis says The population mean is \\(50\\)\nThe alternative hypothesis says The population mean is less than \\(50\\)\n\nIf the null hypothesis is true, then by the Central Limit Theorem the sample distribution of sample means would look like this:\n\n\n\n\n\n\n\n\n\nThe above is true because we have the population standard deviation \\(\\sigma\\) and so we can use a z-value and z-distribution to do our calculations below.\nWe want to know how likely it is to get a sample mean of 48 in this situation.\n\\[\\begin{equation}\nz=\\frac{\\bar x-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n=\\frac{48-50}{\\frac{5}{\\sqrt{40}}}\n=\\frac{-2}{0.7905694}\n=-2.53\n\\end{equation}\\]\nNow you can compute the left tail area which is our p-value in a spreadsheet using the NORMSDIST function:\n=NORMSDIST(z)\nNow putting in the \\(z\\)-value we got:\n=NORMSDIST(-2.53)\nWe get \\(0.0057\\) as a result and this is our P-value:\n\\[\\begin{equation}\nP = \\text{left tail area} =0.0057\n\\end{equation}\\]\nSo based on this our conclusion is that this is strong evidence against the null hypothesis.\n\\[\n\\tag*{$\\blacksquare$}\n\\]\n\n\n\nThe next example is a left tail test where \\(\\sigma\\) is not known, so we use a t-test (use a t-value) in our calculations:\n\nExample 24.2 (Mean Sales For Handbags)  \n\n\nA brand of handbags are marketed through a large number of department stores nationwide. A manager feels the mean sales for all stores in the past year is less than \\(\\$2.65\\times 10^{5}\\). Based on a sample of \\(100\\) stores, the brand’s sales have a mean of \\(\\$2.55\\times 10^{5}\\) and a standard deviation of \\(\\$5.7\\times 10^{4}\\). Test the manager’s claim about the mean sales for all stores.\nSolution:\nWe have \\(\\bar x = 2.55\\times 10^{5}\\), \\(s = 5.7\\times 10^{4}\\) and \\(n=100\\).\nThe claim about the population mean involves \\(2.65\\times 10^{5}\\).\nHere are the null and the alternative hypotheses:\n\\[\\begin{align}\nH_0:\\mu &= 2.65\\times 10^{5} \\\\\nH_a:\\mu &&lt; 2.65\\times 10^{5}\n\\end{align}\\]\n\nThe null hypothesis says The population mean is \\(2.65\\times 10^{5}\\)\nThe alternative hypothesis says The population mean is less than \\(2.65\\times 10^{5}\\)\n\nWe want to know how likely it is to get a sample mean of 2.55^{5} in this situation.\nWe will estimate this by finding a t-value for the sample mean \\(\\bar x\\) and then using the t-distribution to find the left tail area.\nWe have to use a t-value and the t-distribution because we do not have the population standard deviation (\\(\\sigma\\)) in this case and only have a sample standard deviation \\(s\\).\nWe find the t-value using the sample mean \\(\\bar x= 2.55\\times 10^{5}\\), the population mean \\(\\mu=2.65\\times 10^{5}\\), and the sample standard deviation \\(s = 5.7\\times 10^{4}\\):\n\\[\\begin{equation}\nt=\\frac{\\bar x-\\mu}{\\frac{s}{\\sqrt{n}}}\n=\\frac{2.55\\times 10^{5}-2.65\\times 10^{5}}{\\frac{5.7\\times 10^{4}}{\\sqrt{100}}}\n=\\frac{10^{4}}{5700}\n=-1.75\n\\end{equation}\\]\nNow you can compute the left tail area which is our p-value in a spreadsheet using the TDIST function:\n=TDIST(ABS(t), n-1, 1)\nWe put in \\(t=-1.75\\) and \\(n=100\\):\n=TDIST(ABS(-1.75), 100-1, 1)\nor\n=TDIST(1.75, 99, 1)\nWe get \\(0.0416\\) as a result and this is our P-value:\n\\[\\begin{equation}\nP = \\text{left tail area} =0.0416\n\\end{equation}\\]\nSo based on this our conclusion is that this is moderate evidence against the null hypothesis.\n\\[\n\\tag*{$\\blacksquare$}\n\\]"
  },
  {
    "objectID": "simple-regression.html#is-there-a-trend",
    "href": "simple-regression.html#is-there-a-trend",
    "title": "25  Simple Regression",
    "section": "25.1 Is There a Trend?",
    "text": "25.1 Is There a Trend?\nTo understand regression we have to look at the data and think about if there is some kind of trend to it.\nFor example is the data increasing (“trending uphill”) or decreasing (“trending downhill”). If it is then we may be able to use this trend to try to predict what the data is doing. Here is an example of some sales data for some product over several years:\n\n\n\n\n\nyear\nsales\n\n\n16\n45\n\n\n17\n56\n\n\n18\n58\n\n\n19\n58\n\n\n20\n75\n\n\n\n\n\n\n\nHere we have several years of sales for some product. In this case, the units of y are given in thousands of dollars. So that for this product:\n\n45 means $45,000 of sales that year\n56 means $56,000 of sales that year\n\nCan we use this data to predict what the sales will be for the product for the next few years? Say we want to try to predict it for year 21 and year 22 which are in the future.\nIts might be hard to tell just from looking that the data values. Lets look at a graph:"
  },
  {
    "objectID": "simple-regression.html#scatterplot---graphing-the-data",
    "href": "simple-regression.html#scatterplot---graphing-the-data",
    "title": "25  Simple Regression",
    "section": "25.2 Scatterplot - Graphing the Data",
    "text": "25.2 Scatterplot - Graphing the Data\nOne of the first things we can look at is a graph that shows the data, to see if there is some “trend”. So here is the graph of the data:\n\n\n\n\n\nThis is called a scatterplot. A scatterplot is where you display the x and y for each of the data points we have. This is just the familar plot of (x,y) points in the plane that you knew from high school.\n\nthe first point we plotted was (16, 45)\nthe second point we plotted was (17, 56)\nand so on…\n\nEach x-value has an y-value that goes with it.\nSo maybe we can use the x-value to predict the y-value. If the data is not too scattered then this makes sense. In this case the scatter is not to broad.\nIn order to do this, we have to come up with a way of “modeling” the data. In our case we will “model” this relationship between x and y by using a straight line.\nLets see how we can do this."
  },
  {
    "objectID": "simple-regression.html#modeling-the-data-with-a-straight-line",
    "href": "simple-regression.html#modeling-the-data-with-a-straight-line",
    "title": "25  Simple Regression",
    "section": "25.3 Modeling the Data with a Straight Line",
    "text": "25.3 Modeling the Data with a Straight Line\nFirst we need a “model” for what is happening.\nSuppose we try to “model” the relationship between x and y with a straight line. It looks like it is trending up more or less in a line, though maybe not a perfect line.\nHere is an example of one straight line that might do the trick.\n\n\n\n\n\nWe will see a little later where this straight line comes from (its called the regression line), but for right now just notice that this straight line fits the data pretty well but the data is not a perfect fit, and has some “scatter”.\nHow can we use this straight line to predict the “sales” using the “year”?"
  },
  {
    "objectID": "simple-regression.html#doing-predictions-of-y-from-x-using-the-graph",
    "href": "simple-regression.html#doing-predictions-of-y-from-x-using-the-graph",
    "title": "25  Simple Regression",
    "section": "25.4 Doing Predictions of y from x Using the Graph",
    "text": "25.4 Doing Predictions of y from x Using the Graph\nBasically we can predict the “sales” by going to the year we are interested in and going up to the line and taking that value as our prediction of the sales.\nMore or less we are just “extending the trend” we see from the line.\nIn detail:\n\nIf the year is 21 go up to where the line is above 21 for the prediction\nIf the year is 22 go up to where the line is above 22 for the prediction"
  },
  {
    "objectID": "simple-regression.html#making-predictions-using-the-equation-of-a-line",
    "href": "simple-regression.html#making-predictions-using-the-equation-of-a-line",
    "title": "25  Simple Regression",
    "section": "25.5 Making Predictions Using the Equation of a Line",
    "text": "25.5 Making Predictions Using the Equation of a Line\nIt turns out that what we just described can be done with the straight line equation as well.\nSo doing predictions will amount to plugging an x-value in and getting y-value out. We say we are predicting y-values from x-values.\nSo lets look at the equation of the line here. Here it is:\n\\[\ny = 6.2x + -53.2\n\\]\nThe slope is \\(m = 6.2\\) and the intercept is \\(b = -53.2\\).\nNow how do we use this equation for predictions?\nDoing a prediction is easy, you just “plugin” the x and calculate the y.\n\nPredicting Sales when the year \\(x = 21\\)\nWe just plug in \\(x = 21\\):\n\\[\ny = 6.2(x) + -53.2 = 6.2(21) + -53.2 = 130.2+-53.2 = 77\n\\]\n\n\nPredicting Sales when the year \\(x = 22\\)\nWe just plug in \\(x = 22\\):\n\\[\ny = 6.2(x) + -53.2 = 6.2(22) + -53.2 = 136.4+-53.2 = 83.2\n\\]\n\nSo our prediction for year 21 is $77,000 for the sales\nSo our prediction for year 22 is $83,200 for the sales\n\nNow we could go on predicting future years with this line by just plugging in.\nWe can also go back and ask what would this model (our straight line) would have predicted in the past, by plugging in values of x that have already occurred. That way we could see how accurate our model is. We will talk about this notion of accuracy of the model later."
  },
  {
    "objectID": "simple-regression.html#interpretation-of-the-slope-of-the-model",
    "href": "simple-regression.html#interpretation-of-the-slope-of-the-model",
    "title": "25  Simple Regression",
    "section": "25.6 Interpretation of the Slope of the Model",
    "text": "25.6 Interpretation of the Slope of the Model\nOne good way to explain a model that uses a straight line in plain english is to give the interpretation of the slope from the equation being used.\nIn this case, based on the interpretation of slope for straight lines we can say:\n\nFor each additional year, the sales increases by 6.2 units of y.\n\nOr we can say this a little better this way:\n\nFor each year, we expect on average the sales increases by $6,200 units of y."
  },
  {
    "objectID": "simple-regression.html#where-does-the-regression-equation-come-from",
    "href": "simple-regression.html#where-does-the-regression-equation-come-from",
    "title": "25  Simple Regression",
    "section": "25.7 Where Does the Regression Equation Come From?",
    "text": "25.7 Where Does the Regression Equation Come From?\nThe regression equation comes from using software like Excel or Google Sheets or some similar statistics software."
  },
  {
    "objectID": "regression-slope-intercept.html#data",
    "href": "regression-slope-intercept.html#data",
    "title": "26  Regression SLOPE and INTERCEPT",
    "section": "26.1 Data",
    "text": "26.1 Data\nHere is the data set we will work with:\n\n\n\n\n\nyear\nsales\n\n\n16\n53\n\n\n17\n56\n\n\n18\n58\n\n\n19\n58\n\n\n\n\n\n\n\nThe goal here will be to predict the y-value (called \\(sales\\)) from the x-value(called \\(year\\)). We can see already that as the years increase the sales increase as well. So we can roughly guess the trend by just be looking at the data.\nBut we can also do more than just guessing by coming up with a formula that will make our predictions for us when we plug in the year.\nIn order to do that we have to come up with an equation that will allow us to plug in an x-value (\\(year\\)) and get out a y-value (\\(sales\\)). This is what we mean by prediction.\nIn our case we will use a straight line equation, so that is why this process is called linear regression, since linear means “using a line”.\nFirst lets see a scatterplot of the data:\n\n\n\n\n\n\n\n\n\nSo start by copying the data into your spreadsheet in columns A and B:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nyear\nsales\n\n\n\n\n\n\n2\n16\n53\n\n\n\n\n\n\n3\n17\n56\n\n\n\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8"
  },
  {
    "objectID": "regression-slope-intercept.html#finding-slope-and-intercept-of-regression-line",
    "href": "regression-slope-intercept.html#finding-slope-and-intercept-of-regression-line",
    "title": "26  Regression SLOPE and INTERCEPT",
    "section": "26.2 Finding Slope and Intercept of Regression Line",
    "text": "26.2 Finding Slope and Intercept of Regression Line\nNext lets compute the slope and intercept using the functions SLOPE and INTERCEPT in a spreadsheet. Make sure you enter the y cell range in first and then the x cell range when you are using SLOPE and INTERCEPT. And in fact most “regression” formulas for a spreadsheet require y-values range first and x-values range second.\nOkay so here is what using the functions SLOPE and INTERCEPT look like. Slope is labeled m and intercept is labeled b:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nyear\nsales\n\n\n\n\n\n\n2\n16\n53\n\nm\n=SLOPE(B2:B5,A2:A5)\n\n\n\n3\n17\n56\n\nb\n=INTERCEPT(B2:B5,A2:A5)\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the values for after using the formulas:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nyear\nsales\n\n\n\n\n\n\n2\n16\n53\n\nm\n1.7\n\n\n\n3\n17\n56\n\nb\n26.5\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom this we see that the regression equation is given below:\n\\[\nsales= 1.7(year) + 26.5\n\\]"
  },
  {
    "objectID": "regression-slope-intercept.html#making-predictions-using-the-regression-equation",
    "href": "regression-slope-intercept.html#making-predictions-using-the-regression-equation",
    "title": "26  Regression SLOPE and INTERCEPT",
    "section": "26.3 Making Predictions Using the Regression Equation",
    "text": "26.3 Making Predictions Using the Regression Equation\nNext we will make some predictions using the equation above. We want to make predictions for the following values:\n\n\n\n\n\nyear\nsales\n\n\n20\n?\n\n\n21\n?\n\n\n\n\n\n\n\nSo first we set up a part of the spreadsheet to hold our predictions. We call this sections “predictions”. Then we list the x-values that will make predictions for. Then along side that we fill in a formula for the regression equation. We use the entries for the slope and the intercept that we found above:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nyear\nsales\npredictions\n\n\n\n\n\n2\n16\n53\n\nm\n1.7\n\n\n\n3\n17\n56\n\nb\n26.5\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n20\n\n=$E$2*A6+$E$3\n\n\n\n\n\n7\n21\n\n=$E$2*A7+$E$3\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere you should use absolute references for the slope and intercept since if you create your predictions by dragging you do not want the formula to update out of the cells where the m and b are.\nFinally here are the predictions:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nyear\nsales\npredictions\n\n\n\n\n\n2\n16\n53\n\nm\n1.7\n\n\n\n3\n17\n56\n\nb\n26.5\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n20\n\n60.5\n\n\n\n\n\n7\n21\n\n62.2\n\n\n\n\n\n8"
  },
  {
    "objectID": "regression-slope-intercept.html#a-plot-of-the-predictions",
    "href": "regression-slope-intercept.html#a-plot-of-the-predictions",
    "title": "26  Regression SLOPE and INTERCEPT",
    "section": "26.4 A Plot of the Predictions",
    "text": "26.4 A Plot of the Predictions\nBelow we show the regression line\n\\[\nsales= 1.7(year) + 26.5\n\\]\nand the predictions for \\(year=20\\) and \\(year=21\\)\n\n\n\n\n\n\n\n\n\nThe predictions were made by plugging in the x-values into the equation for the line. Here are the details of one of the calculations so you can see what the spreadsheet is doing:\nFor \\(year=20\\):\n\\[\nsales= 1.7(20) + 26.5 = 60.5\n\\]\nSo that point is at \\((20,60.5)\\) on the line.\nRemember these predictions might not be perfect, but they match the trend that we see from the straight line we came up with.\nThe line we are using is called the regression line or the line of best fit or the line of least squares. It goes by a few different names, we will usually call it the regression line.\nThe software comes up with it by fitting a line as best it can between the points so that it is not too far away from them and follows the pattern they form. This is where the term best fit comes from as well."
  },
  {
    "objectID": "simple-regression-significance.html#example-with-small-amount-of-data",
    "href": "simple-regression-significance.html#example-with-small-amount-of-data",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.1 Example With Small Amount of Data",
    "text": "27.1 Example With Small Amount of Data\nLets see some examples. Suppose we have the following data for an ice cream vendor involving the Temperature on a given day and the Gallons of ice cream sold that same day. We might be trying to predict the Gallons from the Temperature.\n\n\n\n\n\nTemperature\nGallons\n\n\n73\n110\n\n\n75\n97\n\n\n77\n105\n\n\n\n\n\n\n\nIts not very much data, modeling based on 3 data points seems dodgy. So we should be careful about this."
  },
  {
    "objectID": "simple-regression-significance.html#regression-line",
    "href": "simple-regression-significance.html#regression-line",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.2 Regression Line",
    "text": "27.2 Regression Line\nLets look at the regression line we get for this data.(Say we ran the regression software in a spreadsheet we would get this):\n\n\n\n\n\nAs you can see the regression line has a negative slope. Here is its equation:\n\\[\nGallons = -1.25(Temperature) + 197.75\n\\]"
  },
  {
    "objectID": "simple-regression-significance.html#should-we-use-the-regression-line",
    "href": "simple-regression-significance.html#should-we-use-the-regression-line",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.3 Should We Use the Regression Line?",
    "text": "27.3 Should We Use the Regression Line?\nShould we use this line for predictions? We should probably be suspicious.\nThe regression line has negative slope!! This says that as Temperature goes up the Gallons goes down.\nThat sounds wrong actually. We expect it to be the other way around, right?"
  },
  {
    "objectID": "simple-regression-significance.html#looking-at-more-data",
    "href": "simple-regression-significance.html#looking-at-more-data",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.4 Looking at More Data",
    "text": "27.4 Looking at More Data\nBefore we decide lets assume we collected more data and now we have the following:\n\n\n\n\n\nTemperature\nGallons\n\n\n73\n110\n\n\n75\n97\n\n\n77\n105\n\n\n65\n95\n\n\n81\n135\n\n\n90\n160\n\n\n82\n120\n\n\n93\n175\n\n\n86\n140\n\n\n79\n121"
  },
  {
    "objectID": "simple-regression-significance.html#regression-line-looks-different-with-more-data",
    "href": "simple-regression-significance.html#regression-line-looks-different-with-more-data",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.5 Regression Line Looks Different With More Data",
    "text": "27.5 Regression Line Looks Different With More Data\nLets see a scatterplot of this data and also look at the regression line now:\n\n\n\n\n\nNow things look quite a bit different. In fact the rest of the data makes it clear that our original model based on just the three data points was not really representative of the rest of the situation."
  },
  {
    "objectID": "simple-regression-significance.html#the-original-data-did-not-show-full-picture",
    "href": "simple-regression-significance.html#the-original-data-did-not-show-full-picture",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.6 The Original Data Did Not Show Full Picture",
    "text": "27.6 The Original Data Did Not Show Full Picture\nYou can see the original 3 points in red below above \\(x=73\\) , \\(x=75\\), and \\(x=77\\):\n\n\n\n\n\nTaken by themselves, the three data points we started with made it look like there was a downward trend, but actually overall there is an upward trend. So the moral of this story is that you cannot trust the regression model if the data set is too small."
  },
  {
    "objectID": "simple-regression-significance.html#is-the-linear-regression-significant",
    "href": "simple-regression-significance.html#is-the-linear-regression-significant",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.7 Is the Linear Regression Significant?",
    "text": "27.7 Is the Linear Regression Significant?\nIt turns out that there is a calculation that will tell us when we have situations like the above, either too little data or maybe no detectable trend given the amount of data.\nThis is called the overall significance test of the model and it uses a p-value. When the p-value is smaller than .05, we say that there is a significant linear relationship between the y-variable and the x-variables.\nWithout getting too technical, we will use this to mean \"its okay to go ahead and use the regression line for predictions if the model accuracy is suitable\". (note: We will check the accuracy using things like \\(R^2\\) and the standard error.) If the p-value is not less than .05, then it is probably not okay to proceed to predictions using the model's regression equation at all.\nUsually you are in a situation like above with either too little data or no discernable trend for the data that you do have. You might be able go back and get more data and redo your analysis."
  },
  {
    "objectID": "simple-regression-significance.html#test-for-overall-significance-of-the-linear-model",
    "href": "simple-regression-significance.html#test-for-overall-significance-of-the-linear-model",
    "title": "27  Is This a Significant Linear Relationship?",
    "section": "27.8 Test for Overall Significance of the Linear Model",
    "text": "27.8 Test for Overall Significance of the Linear Model\nSo in summary:\n\nIf \\(p &lt; .05\\), then there is a significant linear relationship between the y and x’s\n\nMeans it is OK to use the regression equation (if your accuracy allows)\n\n\nIf \\(p \\geq .05\\), then there is not a significant linear relationship\n\nMeans it is NOT OK to use the regression equation\n\n\nWe will see how to find the p-value for the overall significance of the linear model in the spreadsheet examples."
  },
  {
    "objectID": "regression-toolpak.html#the-data",
    "href": "regression-toolpak.html#the-data",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.1 The Data",
    "text": "28.1 The Data\nLets run a regression analysis using the data analysis ToolPak. This add-in is called the Excel Analysis ToolPak in Excel. For Google Sheets it is called the XLMiner Analysis ToolPak. They both work the same way and produce similar output. The links show how to install these tools.\nHere is the data we will work with for our analysis:\n\n\n\n\n\nx\ny\n\n\n16\n45\n\n\n17\n56\n\n\n18\n58\n\n\n19\n58\n\n\n20\n75\n\n\n\n\n\n\n\nHere is a scatterplot of this data:\n\n\n\n\n\n\n\n\n\nMake sure this data is entered into a spreadsheet in columns A and B of the spreadsheet. Include the names “x” and “y” in the first row as well. These are the sometimes called the labels for the variables.\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\nx\ny\n\n\n\n\n\n\n2\n16\n45\n\n\n\n\n\n\n3\n17\n56\n\n\n\n\n\n\n4\n18\n58\n\n\n\n\n\n\n5\n19\n58\n\n\n\n\n\n\n6\n20\n75\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\n10"
  },
  {
    "objectID": "regression-toolpak.html#toolpak-output",
    "href": "regression-toolpak.html#toolpak-output",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.2 ToolPak Output",
    "text": "28.2 ToolPak Output\nRun the Tookpak add-in and select the linear regression tool. For “Input Y Range” enter in B1:B6 and A1:A6 for “Input X Range”.\nYou can click on the “Labels” option since you have included row 1 and this contains the labels “x” and “y” for your data.\nNow choose D2 as the output cell. This is where your regression summary will go. Go ahead and run the analysis and it should output something like this:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n\n\n1\nx\ny\n\n\n\n\n\n\n\n\n\n\n2\n16\n45\n\nSummary\n\n\n\n\n\n\n\n\n3\n17\n56\n\n\n\n\n\n\n\n\n\n\n4\n18\n58\n\nRegression\n\n\n\n\n\n\n\n\n5\n19\n58\n\nMultiple R\n0.913\n\n\n\n\n\n\n\n6\n20\n75\n\nR Square\n0.8335\n\n\n\n\n\n\n\n7\n\n\n\nAdj R Sq\n0.778\n\n\n\n\n\n\n\n8\n\n\n\nStandard Err\n5.0596\n\n\n\n\n\n\n\n9\n\n\n\nObservations\n5\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n\n\n\n11\n\n\n\nANOVA\n\n\n\n\n\n\n\n\n12\n\n\n\n\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n13\n\n\n\nRegression\n1\n384.4\n384.4\n15.0156\n0.0304\n\n\n\n14\n\n\n\nResidual\n3\n76.8\n25.6\n\n\n\n\n\n15\n\n\n\nTotal\n4\n461.2\n\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\n17\n\n\n\n\nCoefficients\nStd Err\nt Stat\nPvalue\n\n\n\n\n18\n\n\n\n(Intercept)\n-53.2\n28.8888\n-1.8415\n0.1628\n\n\n\n\n19\n\n\n\nx\n6.2\n1.6\n3.875\n0.0304\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLets look at some of these numbers and what they mean. We will use only some of them."
  },
  {
    "objectID": "regression-toolpak.html#interpreting-the-output-of-the-toolpak-analysis",
    "href": "regression-toolpak.html#interpreting-the-output-of-the-toolpak-analysis",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.3 Interpreting the output of the ToolPak analysis",
    "text": "28.3 Interpreting the output of the ToolPak analysis\n\nMultiple R is 0.913 in E5.\n\nThis is the absolute value of the correlation coefficient, \\(R\\).\n\nR Squared is 0.8335 in E6\n\nThis is the square of the correlation coefficient and usually denoted by \\(R^2\\). This number tells you how scattered the data is. 1.0 means no scatter, and 0.0 means all scatter\n\nAdjusted R Squared is 0.778 in E7\n\nThis is used for model evaluations in multiple regression. Multiple regression is when you have more than one column of x-variables. Its not useful for simple regression (with one x-variable).\n\nStandard Error of Estimate is 5.0596 in E8\n\nThis is a error estimate for how far off your predictions might be. It is a typical error you might make when using this model for making predictions.\n\nObservations is 5 in E9\n\nThis is how many rows of data you have. Its called the sample size sometimes as well.\n\n\nWe will not use all the output from the summary, but we definitely will need two important parts:\n\nThe equation of the regression line (the slope and the intercept)\nThe p-value that tells us if the model is significant\n\nThe regression equation \\(y=mx+b\\) is easy to identify from the Coefficients:\n\nThe Intercept is -53.2\n\nThis is the \\(b\\) in the equation above\n\nThe slope is 6.2\n\nThis is the \\(m\\) in the equation above\n\n\nNotice that the slope is next to the name of the x-variable, which in this case is just “x”.\nSo the regression equation for this situation is this:\n\\[\ny = 6.2x + -53.2\n\\]\nBut before we start using this equation we need to see if a linear model is valid. This is what we described in the last section about the signficance of the linear model.\nUltimately this tells us if we should use this equation for predictions or not.\nWe can determine this by examining the p-value that goes with the overall significance of the linear model.\nLocating this is explained in the next section."
  },
  {
    "objectID": "regression-toolpak.html#p-value-for-overall-significance-of-the-linear-model",
    "href": "regression-toolpak.html#p-value-for-overall-significance-of-the-linear-model",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.4 p-value for Overall Significance of the Linear Model",
    "text": "28.4 p-value for Overall Significance of the Linear Model\nIf you examine the output of the regression analysis you will see this in the middle of the output some cells that look like this:\n\n\n\nF\nSignificance F\n\n\n\n\n15.0156\n0.0304\n\n\n\nThe thing we want is labeled “Signficance F” in this output. Almost everyone else calls this the “p-value” or the “p-value for the significance of the linear model”. Here it is: 0.0304.\nThis p-value (if it is small enough) will tell us if there is a significant linear relationship between the y and the x. This notion of a significant linear model was discussed in the last section where we gave a graphical example that used a very small amount of data.\nHere is the official test based on the above p-value and how we use it."
  },
  {
    "objectID": "regression-toolpak.html#test-of-overall-significance-of-the-linear-model",
    "href": "regression-toolpak.html#test-of-overall-significance-of-the-linear-model",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.5 Test of Overall Significance of the Linear Model",
    "text": "28.5 Test of Overall Significance of the Linear Model\n\nIf \\(p &lt; .05\\), then there is a significant linear relationship between the y and x\n\nMeans it is OK to use the regression equation (if your accuracy allows)\n\n\nIf \\(p \\geq .05\\), then there is not a significant linear relationship between the y and x\n\nMeans it is NOT OK to use the regression equation\n\n\nSince \\(p = 0.0304\\) and this is less than \\(.05\\), we conclude there is a significant linear relationship between y and the x. So it makes sense to use the regression equation for predictions.\nNow that we know the linear model is significant, lets use the equation to predict y if \\(x=6\\):\nThat would be:\n\\[\ny = 6.2x - 53.2= (6.2)(6)-53.2 = -16\n\\]\nNow if the p-value had not been small enough (less than \\(.05\\)) you would not use the equation for predictions this way. Remember this test is for the validity of using a linear model (a straight line) to model your data. If the linear model is not significant, then you have no business using the equation for predictions.\nKeep this in mind, you always need to examine this p-value to make sure you are working with an appropriate model."
  },
  {
    "objectID": "regression-toolpak.html#example-where-the-linear-model-is-not-significant",
    "href": "regression-toolpak.html#example-where-the-linear-model-is-not-significant",
    "title": "28  Using the ToolPak for Regression Modeling",
    "section": "28.6 Example Where The Linear Model is Not Significant",
    "text": "28.6 Example Where The Linear Model is Not Significant\nLet’s look at the example from a previous chapter where there was just 3 data points.\n\n\n\n\n\ntemp\ngallons\n\n\n73\n110\n\n\n75\n97\n\n\n77\n105\n\n\n\n\n\n\n\nHere is a scatterplot of this data:\n\n\n\n\n\n\n\n\n\nMake sure this data is entered into a spreadsheet in columns A and B of the spreadsheet. Include the names “temp” and “gallons” in the first row as well.\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n1\ntemp\ngallons\n\n\n\n\n\n\n2\n73\n110\n\n\n\n\n\n\n3\n75\n97\n\n\n\n\n\n\n4\n77\n105\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun the Tookpak add-in and select the linear regression tool. For “Input Y Range” enter in B1:B4 and A1:A4 for “Input X Range”.\nYou can click on the “Labels” option since you have included row 1 and this contains the labels “temp” and “gallons” for your data.\nNow choose D2 as the output cell. This is where your regression summary will go. Go ahead and run the analysis and it should output something like this:\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n\n\n1\ntemp\ngallons\n\n\n\n\n\n\n\n\n\n\n2\n73\n110\n\nSummary\n\n\n\n\n\n\n\n\n3\n75\n97\n\n\n\n\n\n\n\n\n\n\n4\n77\n105\n\nRegression\n\n\n\n\n\n\n\n\n5\n\n\n\nMultiple R\n0.3812\n\n\n\n\n\n\n\n6\n\n\n\nR Square\n0.1453\n\n\n\n\n\n\n\n7\n\n\n\nAdj R Sq\n-0.7093\n\n\n\n\n\n\n\n8\n\n\n\nStandard Err\n8.5732\n\n\n\n\n\n\n\n9\n\n\n\nObservations\n3\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n\n\n\n11\n\n\n\nANOVA\n\n\n\n\n\n\n\n\n12\n\n\n\n\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n13\n\n\n\nRegression\n1\n12.5\n12.5\n0.1701\n0.751\n\n\n\n14\n\n\n\nResidual\n1\n73.5\n73.5\n\n\n\n\n\n15\n\n\n\nTotal\n2\n86\n\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\n17\n\n\n\n\nCoefficients\nStd Err\nt Stat\nPvalue\n\n\n\n\n18\n\n\n\n(Intercept)\n197.75\n227.3855\n0.8697\n0.5443\n\n\n\n\n19\n\n\n\ntemp\n-1.25\n3.0311\n-0.4124\n0.751\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this case the p-value for the significance of the model is given in I13 and the value is \\(0.7509899\\). Since this is bigger then \\(.05\\), the is not a significant linear relationship between \\(temp\\) and \\(gallons\\).\nSo this means we should NOT use the regression equation here to make predictions.\nWe have already seen that in fact the regression equation doesn't make sense once we include more of the data. The slope of the relationship here should be positive since as \\(temp\\) goes up it is likely that \\(gallons\\) would go up as well since this is gallons sold."
  },
  {
    "objectID": "rsquared.html#how-good-is-the-fit",
    "href": "rsquared.html#how-good-is-the-fit",
    "title": "29  R-Squared (\\(r^2\\))",
    "section": "29.1 How Good is the Fit",
    "text": "29.1 How Good is the Fit\nYou might have wondered what \\(r^2\\) tells you in the regression analyses output. It tells you about how tight the fit is for your scatter.\n\nIf \\(r^2 \\approx 1.0\\), then all the points will be on a line and their will be no scatter.\nIf \\(r^2 \\approx 0.0\\), then you cannot detect where the line would even be. It is all scatter.\n\nThe scatter affects the predictability and accuracy of your model. If you are using the regression equation to make predictions, you should be mindful if the \\(r^2\\) is low, and whether or not that will be an issue for your situation.\nThe question of whether the \\(r^2\\) is too low depends on the context and the situation. Sometimes it is unacceptable to have a low \\(r^2\\) but sometimes it is fine.\nYou will have to look at your situation to decide whether your model provides benefit even if it is not very accurate when it has a low \\(r^2\\)."
  },
  {
    "objectID": "rsquared.html#r2-examples",
    "href": "rsquared.html#r2-examples",
    "title": "29  R-Squared (\\(r^2\\))",
    "section": "29.2 \\(r^2\\) Examples",
    "text": "29.2 \\(r^2\\) Examples\nHere are some pictures that show different \\(r^2\\) values:\n\n\n\n\n\n\n\n\nGradually more and more scatter.\n\n\n\n\n\n\n\n\nAnd more and more…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen \\(r^2\\) is close to \\(0\\), it is very difficult to see any trend:"
  },
  {
    "objectID": "rsquared.html#explained-variation",
    "href": "rsquared.html#explained-variation",
    "title": "29  R-Squared (\\(r^2\\))",
    "section": "29.3 Explained Variation",
    "text": "29.3 Explained Variation\n\\(r^2\\) is sometimes called the explained variation.\nThis comes from this interpretation:\n\nIt is the percent of the variation in y that is explained by using x (and a linear model)\n\nThe idea is that some of the variation in y can be understood by using a linear regression model, but not all of it. The explained variation is just the notion of how good that linear regression model is.\nSo if you see this:\n\n90% of the variation in y is explained by x you will know that it just means \\(r^2=.90\\)\n45% of the variation in y is explained by x you will know that it just means \\(r^2=.45\\)\n\nWe won’t use this wording much in this book, but it comes up when people talk about and interpret regression results."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Xie, Yihui. 2015. Dynamic Documents with R and\nKnitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.\n\n\n———. 2019. Bookdown: Authoring Books and Technical Documents with r\nMarkdown. https://CRAN.R-project.org/package=bookdown."
  },
  {
    "objectID": "z-table.html",
    "href": "z-table.html",
    "title": "Appendix A — Z Table For Standard Normal Distribution",
    "section": "",
    "text": "Here is a version of the z-table that we use.\nThis table matches the formula NORMSDIST from Excel and Google Sheets.\nThis part is for negative z-values:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n\n\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n\n\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n\n\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n\n\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n\n\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n\n\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n\n\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n\n\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n\n\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n\n\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n\n\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n\n\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n\n\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n\n\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n\n\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n\n\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n\n\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n\n\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n\n\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n\n\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n\n\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n\n\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n\n\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n\n\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n\n\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n\n\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n\n\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n\n\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n\n\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n\n\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\n\n\n\n\n\n\n\nAnd this part is for positive z-values:\n\n\n\n\n\n\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n\n\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n\n\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n\n\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n\n\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n\n\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n\n\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n\n\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n\n\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n\n\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n\n\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n\n\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n\n\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n\n\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n\n\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n\n\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n\n\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n\n\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n\n\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n\n\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n\n\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n\n\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n\n\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n\n\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n\n\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n\n\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n\n\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n\n\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n\n\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n\n\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n\n\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n\n\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990"
  },
  {
    "objectID": "lines.html",
    "href": "lines.html",
    "title": "Appendix B — Straight Line Review",
    "section": "",
    "text": "In this section we give some examples of straight lines and also look at the interpretation of slope.\nSince we will use straight lines to model data when there is a trend (This is called regression) it is important that we understand what slopes mean and what the equations look like for different lines.\nFor slopes:\n\na positive slope means increasing or uphill trend\na negative slope means decreasing or downhill trend\n\nHere are some examples:\nExample 1\n\n\n\n\n\nThe equation is:\n\\(y = 2x + 3\\)\n\nThe slope is: \\(m = 2\\)\nintercept is: \\(b= 3\\)\n\nInterpretation of slope\nFor each additional unit of x, there is an increase of 2 units of y\nExample 2\n\n\n\n\n\nThe equation is:\n\\(y = -1x + 5\\)\n\nThe slope is: \\(m = -1\\)\nintercept is: \\(b= 5\\)\n\nInterpretation of slope\nFor each additional unit of x, there is an decrease of 1 units of y\nExample 3\n\n\n\n\n\nThe equation is:\n\\(y = 2.1x + 0.5\\)\n\nThe slope is: \\(m = 2.1\\)\nintercept is: \\(b= 0.5\\)\n\nUnits\nSuppose \\(x\\) = advertising expenditures (in $000s, so thousands of $)\nSuppose \\(y\\) = sales (in $0 000s, so in ten thousands of $)\n\nSo if \\(x = 1.2\\) that stands for $1200\n\nIf \\(y = 5.6\\) that stands for $56,000\n\nInterpretation of slope\nFor each additional unit of x (so each additional $1000 dollars spent on ads), there is an increase of 2.1 units of y (so an increase of $21,000 in sales)"
  }
]